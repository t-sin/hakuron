# 序文の前に

2021年9月。北九州市の植物園でこのイントロダクションを書いている。

植物園、というか自然公園みたいなこの場所にはフリーランスの仕事で来ている。公園を大きく使ったナイトウォークのようなイルミネーションのようなイベントで、そのための音楽やSEを流すためのシステムを作る仕事である。仕事の半分くらいはスピーカーをどこに配置するかとか、どの機材を使うかとかそういう話なのだが、もう半分はその沢山あるスピーカーにどう音を割り振ったり、パソコンを起動したら自動的に音が鳴り始めるようにするためのプログラムを作る作業になる。

制御のためのソフトウェアはCycling'74社のMaxという音声処理が得意なマルチメディアプログラミング環境で構築している。長い歴史を持ち、現在音楽のためのプログラミング環境としては（知る限り）最も多く使われており、個人的には2015年から使い始めたこのMaxというソフトウェアを使うと、たとえば展示空間にスピーカーを10個とか（それも、いわゆるサラウンドとかとは全然違うレイアウトで）配置してそれぞれに違う音を同期して流したりすることができる。あるいは、映像を生成するコンピュータからネットワーク経由で特定の信号を受け取ったら特定の効果音を流すようにしたり。

なんだか言葉にすると大したことがない仕事のように聞こえる。実際、プログラムを書く作業自体は主観的には大したことがないのだ（ソフトウェア特有のニッチな問題やらバグは細々あるにしても）。こんな作業でお金をもらってしまっていいんだろうかと思う時もある。

しかし実際のところ似たような仕事ができる人はそこまで多いわけでもないらしい。たとえば、仕事を受けようとしたが予定が埋まっているときに別の似たような職能を持った人を紹介しようと思っても、パッと思いつく人はそう多くない。

これは、自分がこうした仕事に慣れすぎてしまったのだろうか。半分はそうなのだろうが、この仕事をしているとやはり考えざるを得ない疑問は、コンピューターはなんでもできる装置のはずなのに、たかだか沢山のスピーカーに同時にたくさん音楽を流すぐらいのことに、どうしていちいちこんな専用の（しかも有料の）ソフトウェアを使ってカスタムツールを使ってプログラムを作るような手間がかかる作業になってしまうのだろう、ということなのだ。

これは別に、使うスピーカーが多いから必要なコンピューター処理能力が大きい、という話でもない。たとえば、映像インスタレーション作品でどうしてもフォーマット的に3chのスピーカーを制御したい、となったときにも、大体10chの時と同じくらいの面倒臭さが発生する。2chが3chになったりするだけで、普通の音楽制作ソフトウェアでは扱いづらくなる。なんでmacOSでファイルを選択してスペースバーを押したら音声ファイルが再生されるように、物理的なセンサーに触ったら音声ファイルを再生する程度のことに労力が必要なのか。なんでエクセルファイルをちょっと編集するぐらいの手間で10chのスピーカーに音声ファイルを割り振れるようにならないのか。

この疑問こそが、おそらくはインフラストラクチャやフォーマットの持つ力というものの説明なのだろう。つまり、人々は2chのステレオ音声のフォーマットがすでにあるから2chステレオで音楽を作る。作るためのツールも2chが一番主流なのでそれが最も作りやすいように良心的な配慮をしてしまう。それに、いかに音楽や芸術表現が新しさを欲するものだとしても、とりあえずはその2chのフォーマットの中で表現が可能な新しさであれば問題にはならない。そして、別に3ch以上の音声フォーマットも表現として "不可能なわけではない"。ただ、ちょっと手間がかかるのだ。

技術決定論者/あるいはマルクス主義者風の言い方をすればインフラストラクチャ:下部構造が上部構造——、つまり音楽表現とかを規定するということになるのだろうか。おそらくはそうではない。インフラストラクチャは表現を完全に縛りはしないが**誘導**する。そしてその誘導方向は既存の上部構造によって作り出されるものであり、互いに循環し合いながら徐々に路面は踏み固められていく。

こうした実感を持つようになってきたのは自分で音楽のためのプログラミング言語を作り始めようと構想しはじめた2018年の後半ごろからだった。2018年の9月から11月にかけて、筆者はSchool for Poetic Computation(SFPC)という、ニューヨークにあるアーティスト・ラン・スクールへ留学した。SFPCはテクノロジーと表現を批評的に、かつ実践的に学ぶ私学校のような場所で、年に2回、20人ほどの学生（10代から50代まで幅広い）が集まり、OpenFrameworks[^openframeworks]を用いたグラフィックプログラミングから技術批評の文献購読までを3ヶ月間、対話を交わしながら進めていくものだった。

[^openframeworks]:openframeworks

筆者はそれまで、物理モデリング楽器を物理的な要素で再構築するインスタレーション作品の制作や、オーディオフィードバックを主要素とする電子音響楽器の開発とそれを用いた即興演奏などを中心に活動してきた。

これらの作品制作への大元のモチベーションも詰まるところ、先述したどれだけ工夫したプログラムを作ったところで全ては2chのステレオPCMサウンドというフォーマットに収束してしまうことへの窮屈さから来る、より異なる音楽表現の可能性の追求であった。つまりインスタレーション作品も、オーディオフィードバックを用いる電子楽器も、コンピューターにスピーカーを繋げるだけでは実現不可能な表現領域を探索することに意義を見いだしていた。

しかし同時に、音楽のフォーマット（あるいは、より広範な意味合いでの "形式"）から離れたところで、インスタレーションや、展示、あるいは即興演奏のイディオムという異なる形式へと従属する対象が変わっただけのようにも感じていた。そうした疑問を抱えながら過ごしたSFPCでの授業は全くこれまでと違う考え方を自分に与えてくれた場所であった。

SFPCの入居しているウエストベス・アーティスツ・コミュニティという建物は、元々1890年代から1960年代までベル研究所の建物だった場所で、有名なところではショックレーらによる世界で初めてのトランジスタが発明された場所でもある。そして同時にこの場所はニューヨークのテクノロジー・アートの歴史の中心地と言ってもよい歴史的な経緯を持つ場所でもある。

ベル研究所のエンジニア、ビリー・クルーヴァーは美術家のロバート・ラウシェンバーグとともに、60年代にExperiments in Arts And Technology(E.A.T)というアーティストとエンジニアの共同作業のための集団を組織し、《九つの夕べ》や、1970年の大阪万博ペプシ館の演出を担当するなど、のちのテクノロジーを用いた芸術制作へと大きな影響を与えている。こうしたニューヨークにおける技術者と芸術家の共同作業は、ラウシェンバーグを始め、ウエストベスにのちに入居するダンサーのマース・カニングハムや、彼らとの共同作業も行った作曲家のジョン・ケージやデイヴィッド・チューダーといったアーティストの参加したブラックマウンテン・カレッジ、またケージの参加したフルクサスのような、反制度、反形式的な思想や運動を背景としていることが特徴であり[^institution]、これはたとえば人類学者のジョージナ・ボーンが「Rationalizing Culture」（「文化を合理化する」）で、フランスの電子音楽研究所において70〜80年代にピエール・ブーレーズのような作曲家が電子音楽のための技術を、現代音楽という積み重ねられてきた歴史の上で正当化する過程を描いた様子とは大きく異なる[@Born1995]。

[^institution]: ただし実際のところ、E.A.Tのような試みは同時に、アーティストと大企業との付き合い方や資本主義との向き合い方という面で困難を呈しもしていた。[@sec:intermission]を参照。

SFPCのプログラムはこうした歴史的背景をもとに、ブラックマウンテン・カレッジのような既存の教育の枠を外し、生徒が互いに教え合う機会を多く設けた"Horizontal Pedagogy"(http://taeyoonchoi.com/2012/05/notes-on-critical-pedagogy/)と呼ぶ学びの姿勢を重視したものであり、かつ、大阪万博を一つのピークとして捉えられる、60年代のテクノロジーアートにおける、表現に先行して技術を無批判に用いることや、大規模化するごとに資本主義に迎合していってしまう傾向[^mediaarthistory]への内省を踏まえたものとなっている。技術を用いる際に暗黙的に発生する政治性に自覚的になり、また技術を与えられたブラックボックスとせず、すでにライブラリやツールが存在しているものだったとしても一度自分の手で作り直すことによって体でその内容を理解することで、異なる技術のエコシステムの可能性を想像することができるようになるというわけである。

[^mediaarthistory]: たとえば、[@Ma2014,58p]の坂根厳夫の引用では、70年代はじめのオイルショックや環境問題を単に発した科学技術自体への批判との共鳴が指摘されているし、大阪万博ペプシ館でのスポンサーによる会期中のプログラム中断と、E.A.Tのその後の活動の衰退をあげることができるだろう。

それゆえ、SFPCで教える講師達の活動形態も、必ずしも作品を作って美術館に展示することが中心なわけではない。OpenFrameworksでほぼ毎日短いCGアニメーションを作り投稿し続けるZachaly Liebermanや、CPUの動作原理を餃子作りに見立てた"CPU Dumpling"ワークショップを行うTaeyoon Choi、ポストコロニアルスタディーズをベースに、白人中心主義的なコンピューター文化批判のインスタレーションやZineを制作するAmerican Artist、100年以上ただ時を刻むだけのカウンターのようなオーバー・エンジニアリングなツールを自宅の工房で作って自分たちで売り続けるCW&T……のように、多様な活動を見せる彼/彼女らの活動を通して（それでどうやって生計を立てられるかはともかくとしても）テクノロジーと社会の関係性への向き合い方は必ずしもアートという閉じられた空間の中だけで行うものでなくてもよいのだと実感させられた。

こうした経験が音楽のためのプログラミング言語という実に微妙な領域の制作へ筆者が本格的に入っていくきっかけとなった。

詰まるところ、"どれだけ工夫したプログラムを作ったところで全ては2chのステレオPCMサウンドというフォーマットに収束してしまうことへの窮屈さ"に対して真に向き合うには、何が社会的にそのフォーマットを構築しているのかについて突き詰めて考える必要があったのだ。違う表現の形式へスライドしても結局その形式の束縛を受けるだけになってしまう。ならばやるべきは制作を無意識的に支配している形式や制度そのものの脱構築に他ならない。つまり筆者にとって音楽プログラミング言語の制作とは音楽を生み出す下部構造＝インフラストラクチャになりうる道具自体を自らの手で作ることを通じて、異なる音楽の形式や制度そのものをメタ的に制作する芸術実践でもある。


<!-- 
この大きな問題意識のもと、筆者の音楽プログラミング言語制作の目標はその中で二転三転を経てmimiumという現在のプロジェクトに落ち着く。始めにある程度まとまった人数に対して言語設計の話を持ち出したのは、SFPC滞在期間はじめの自己紹介兼、3ヶ月の間に何をやろうとしているかのプレゼンテーションをする場所だった[^meetthestudent]。そこでは、1つのソースコードに対して複数の処理系を通すことで異なる音楽が発生するという、どちらかといえばCode Poetry[^CodePoetry]などの詩としてのソースコードとその処理系の関係性、コードを書く人と処理系を作る人のオーサーシップの関係性に焦点を当てたものだった。結局SFPCの滞在期間中に制作したのはよりハードウェアのレイヤーでコンピューターの構造と音楽という時間芸術の形式の関係性を問い直すものになり[^edtac]、言語設計を実際に始めるのは日本に戻った2019年からになる。

[^meetthestudent]: SFPC 2018 fall classにおけるMeet the Studentsという公開イベント。YoutubeのURLとSpeakerDeckのスライドを貼る

[^CodePoetry]: プログラミング言語のソースコード自体を詩のように扱う芸術の形式。実際には実行できないがソースコードの見た目を模したもの、実行することで初めて詩として読めるもの、ソースコードとしても可読性があり、実行することでさらにグラフィックを生成するものなど様々な種類がある。[@Montfort2013]などを参照。

[^edtac]: Electronic Delay Time Automatic Calculator(EDTAC)という作品。修士論文[@Matsuura2019mathesis]や2019年JSSA研究会での[@Matsuura2019jssa]を参照。

2019年ごろの設計初期段階では、Mayer、ChughらのSketch-n-Sketch[@Mayer2018]や、JacobsらのPara[@Jacobs2017]、橋本麦によるGlisp(NiU)[^Glisp]など、グラフィック生成のためのアプリケーションにおいて、ソースコードの編集と直接操作(いわゆるDirect Manipulation：Adobe IllustlatorやMicrosoft PowerPointにおけるベクター図形編集のような、図形の要素をGUIで直接サイズ調整できるような種類のアプリケーション)を組み合わせたり、相互に行き来できるソフトウェアを、音楽プログラミングの領域においても実現できないかというアイデアが中心に置かれていた。

[^Glisp]: https://glisp.app。なお、橋本もSFPCへの滞在経験があるほか、Jacobsは筆者の滞在期間中にフィールドワークの一環でSFPCを訪れている。

実際、この提案は2019年情報処理推進機構未踏IT人材発掘・育成事業という、革新的なソフトウェア制作に対する支援事業に採択され、その当初のアイデアはプログラミング言語設計とそのソースコードをグラフィカルに編集できるソフトウェアという2つのプロジェクトを並列して行うものになっていた。[^mitou]

[^mitou]: 未踏IT人材発掘・育成事業：2019年度採択プロジェクト概要（松浦PJ）(https://www.ipa.go.jp/jinzai/mitou/2019/gaiyou_tk-1.html)を参照。また同時期に情報処理学会音声情報処理研究会にて同様の案についてのポスター発表を行っている[@Matsuura2019MUS]。

しかし結果として、2019年6月から2020年2月までの同事業でのディスカッションを中心に実装を進める中で、筆者の興味関心は徐々にその根幹であるプログラミング言語の設計そのものに移ることになった。ひとつの理由は、音声信号は、（考えてみれば当たり前だが）グラフィックにおけるコードと直接操作の相互利用ツールと異なり、**直接操作**など不可能である、ということに気づいたことにある。我々が音楽制作ソフトウェアで波形をマウスで切り貼りしているのは言うなれば音声データのありうる表象のかたちのうちのひとつでしかなくて、空気の振動それ自体ではない。音楽プログラミング言語で表現しようとしているデータ形式そのものも音そのものではない。 -->


# 序文

本研究は音楽土木工学という、未だ存在しない学問領域を、音楽のためのプログラミング言語mimiumの設計と開発を通じて描き出す試みだ。この論文の中で筆者が提起しようとしている音楽土木工学とは、その名前の通り土木工学——つまり街における道路のようなインフラストラクチャ設計や、未来の街の姿自体を検討する都市計画、そのための構造力学や材料工学といった分野を音楽という領域に当てはめて考えてみるというアナロジーに基づくものだ。

では、音楽における**土と木**、インフラストラクチャとはいったいなにか？

例えばわかりやすいのは音楽を流通させるストリーミングサービスだ。まだ音楽の流通がCDや、（違法なものを含め）ファイル単位でのデータ配信が主流だった2005年に、クセックとレオナルドはコンピューターやインターネット技術の発展の先に音楽の姿は「水のような音楽」になると予測した[@Kusek2005]。月単位で水道代を払っていれば蛇口をひねれば水が出るように、特定のサービスと契約していればクリックすれば好きな音楽がいつでも聴き放題である今日の音楽ストリーム（川）の姿は彼らが予想した未来そのものである。私たちの音楽を聴く生活のあり方は、それを運ぶサービスという名の川が整備されることによって少なからず変化した。これだけでも音楽に関わる工学的研究において、そのコンテンツにだけ焦点を当てるのではなく、ある技術そのものに音楽に関わる要素がなくとも、その技術が用いられた音楽のインフラストラクチャに目を向けることには音楽の未来を考えるにあたって価値あることだと言えるだろう。

一方で私は、音楽土木工学という言葉を単にSpotifyやApple Musicのような音楽流通サービスを支える技術について考えようというだけの意味で提起しようとしているのではもちろんない。私が意図する音楽における土と木とはむしろ、**音楽のために作られたわけではないが、それでも音楽のあり方に大きく影響を与えているテクノロジーやインフラストラクチャ**に重点をおいている。コンピューターの構造は音楽制作に使うために設計されたのではないし、インターネットは音楽配信の方法を変えるためだけに生み出されたのではないが、確実に音楽の制作と聴取の変容に影響を与えている。

2021年現在、音楽を聴いたり、演奏したり、作ったりする上で、コンピュータが一切関与しない、という状況を考えるのは難しくなっている。作曲にはProtoolsやCubaseに代表されるDAW（Digital Audio Workstation）ソフトウェアを使用し、配信にはApple MusicやSpotifyのようなストリーミングサービスを通じて、デジタルデータという形で音楽は配布される。最終的に、コンピューターやスマートフォン上のソフトウェアでそのデータをデコードし、DAC(Digital-Analog Converter)によって電気信号へと変換され、その信号はスピーカーへと送られようやく空気の振動になり、私たちの耳へ届く。スピーカーの中にさえデジタル信号処理(DSP:Digital Signal Processing)用のチップが入っていて計算によって音質の調整をしていることも珍しくはない。2020年以後のコロナウィルスの影響も含めれば、クラシック音楽のコンサートさえもその場で空気の振動を体感することよりも録画録音されたものをコンピューターを通じて摂取することの方が多くなってしまったかもしれない。とかく音楽文化を見れば、マーク・ワイザーの提唱したユビキタス（Ubiquitous:遍在する）・コンピューティング[@Wiser1999]の概念は字義通りには達成されたようにも見える。

それでも、そうやってコンピューターという、理論的にはなんでも可能なはずの装置を通じて生み出され届けられる音楽の聴取の形式自体は、電子計算機が作られてから70年が経とうというのに、2chステレオで5〜10分程度の曲という、コンピューター以前の録音音楽によって形成されたフォーマットから大きく変化していない。

音楽表現を支えるための道具やインフラストラクチャは、常に進歩的に新しい表現を可能にしてきたように歴史の中で物語られるものの、実際のところその研究や道具は何を理想としていて、誰がどう方向付け形作るものなのだろうか。それは音楽家自身によって変化を促せるような対象なのだろうか？

音楽土木工学とは、こうした問題意識をもとに、特に既存の音楽に関わる工学的研究との違いにおいて、対象とする技術要素の違いにおいて特徴付けられる学問である。音楽土木工学はテクノロジーを音楽に応用するのではなく、**音楽の形式の規定に大きく関わるが、必ずしも音楽のために作られたわけではない汎用的なテクノロジー**を、改めて音楽という視点から作り直すことを主眼に置く。

音楽のための工学的研究は例えば録音技術の研究や音楽/音響心理学のような、必ずしもコンピューターを必要としない研究領域も当然大小存在しているものの、特に現代においては先述したユビキタス・コンピューティング的状況を考えれば、音楽のための道具やインフラストラクチャを作る研究としてもコンピューターを音楽に用いる研究は中心的研究領域となるだろう。

この中でコンピューターを用いるテクノロジー、つまり情報技術を音楽に応用する、という、音楽土木工学と対照的な立場として挙げられる代表的研究領域が、いわゆる音楽情報抽出（Music Information Retrieval:MIR）と呼ばれる分野だ。MIRという研究分野ではコンピューターという0/1で音楽に関わるあらゆる種類のデータを表現することが試みられる。 例えば、2chの音声信号から録音時の個別の楽器の音声信号を抽出するような音源分離技術、Text-to-Speech、音楽の曲調の変更、といった、音楽/音声信号に含まれているリズム、ピッチ、メロディ、さらには音色や曲調のような抽象的なパラメーターを統計的手法を用いて抽出したり、逆にそうしたパラメーターをもとに音声情報を変換したり合成するアプローチの研究がなされている。これは言い換えれば人間の耳のような生理的器官の機能や、脳の認知的機能をモデル化することが念頭に置かれた手法である。それゆえ、近年の機械学習技術の発展とも相まって、音声や音楽に関わるコンピューティング技術の中でもその存在感をますます大きくしている。

一方で音楽土木工学が対象とする技術的要素は例えば、コンピューターアーキテクチャやオペレーティング・システム、プログラミング言語（の設計とその処理系開発）、プロトコルやデータフォーマットといったものだ。こうした技術はとくに日本では低レイヤーと呼ばれることもある、コンピューターの技術における抽象化のピラミッドにおいて比較的下層に位置するものだ。こうした機関的、まさにテクノロジーにおける土と木に相当する要素を、音楽のようなある特定の領域のために再考するというアプローチは、近年ではさほど特殊な考え方ではなくなってきている。

その理由のひとつは、コンピューターの中で用いられる技術を段階的に抽象化し、各レイヤーにおける技術的最適化を試み、下層の技術はその上で何を表現するかを考えることはしなくても良いという、これまでの考え方が通用しなくなってきたことだ。

例えば画像データの処理や機械学習のような、並行して同時に計算可能なタスクはコンピューターアーキテクチャ、つまりCPUや記憶装置など、コンピューターを構成するハードウェア群自体の設計を並行処理に適したユニット（例えば、GPU）を利用することで圧倒的に処理速度を向上させることができる。この性能向上の程度は今日もはや、上層のソフトウェアのアルゴリズムだけで改善できる程度を大幅に上回っている。

コンピューターアーキテクチャ設計の分野においては、これまでムーアの法則と呼ばれる、ICチップにおけるトランジスタの集積率が年々指数関数的に増加することが見込まれてきた傾向が今後頭打ちになるだろうといった背景[^denard]をもとに、近年ではドメイン固有アーキテクチャ（Domain Specific Architecture:DSA）と呼ばれる、特定の処理のために専用のプロセッサを計算機に実装することの必要性が提起されている[@Hennesy2017]。DSAの代表的な例としてはGoogleによる機械学習に特化した演算ユニットであるTPU（Tensor Processing Unit）が挙げられる[@Google2018]。

[^denard]: 実際、デナード則という、集積率を上げて処理性能が向上しても電力消費は一定のままであるという法則は2006年ごろから崩れているという見解がなされている[@Hennesy2017]。

こうした処理性能の話に限らずとも、例えばArduinoに代表される、趣味やアーティストの作品制作のために作られた、マイクロコントローラ（AVRやPICに代表される、OSなどを用いない小規模のコンピューター）を用いた電子工作を簡便化した環境は、AVRマイコンという技術的要素と、必要最低限な標準的な入出力の規格化、ハードウェアのオープンソース化、初心者にも親しみやすい開発環境ソフトウェア（IDE）という、各種レイヤーにすでに存在していた技術をパッケージにすることで多くの非専門家に電子工作の門戸を開いてきた。同様に、プログラマブルではあるが、ある程度特定の目的に特化したミニコンピューターという系列で、音楽や楽器制作への利用を念頭においたものとしてBelaのようなハードウェアも挙げられる[@Bela2018]。Belaは、BeagleBone Blackという、Linux（オープンソースのオペレーティングシステム）を搭載する既存のオープンソースミニコンピューターのための、音声入出力インターフェースを備えた拡張ボードだ。その特徴は単にハードウェアだけがプロダクトに含まれているのではなく、USBケーブルで自分のラップトップなどと接続すると、Arduinoと似たような形で、そのラップトップのWebブラウザ上から簡単にプログラムを書き換えられるような開発環境がセットになっている点である。さらに、音声信号処理において特有の問題である入力データが出力に反映されるまでの遅延を極力取り除くために、オペレーティングシステムの機関部分（カーネル）にXenomaiと呼ばれる拡張が加えられていることも特徴のひとつだ。このハードウェアとカスタムOSの合わせ技を利用することでBelaは、より高速なCPUを積んだラップトップやデスクトップコンピューターでも実現できないような低遅延のシステムを構築することができる。

このように、これまで利用目的を問わずに万能に対応できるよう構築されていたハードウェアとOSのような基幹的な技術要素を（例えば音楽といった）特定の目的のために、部分的に作り替えてみたり、開発環境ソフトウェアものような高レイヤー技術も含めた複合的な組み合わせを検討することによって特定の課題が解決される可能性は大いに増えているし、電子回路やハードウェア設計、実装自体の個人レベルでの取り組みのハードルが下がってきたこともこれらの傾向を後押ししている。


# 研究領域のデザイン

このように私が提起しようとしている音楽土木工学は、音楽に関わる工学の異なる関わり方の追求ではあるが、その理論的な基盤は工学や科学というよりもデザイン学にある。

デザインというとグラフィックデザインやインテリアデザインのような視覚的表象の操作や、あるいはインターフェースデザインやWeb/アプリケーションのデザインのように、ユーザーの認知的特性に基づいた道具の操作方法の設計一般のような分野を想起してしまうが、デザイン学問は歴史の中でその意味を単に良い製品の創出といった側面だけではなく、社会システムのような抽象的なものを含めた、人工物の創出一般に関する方法論としての性質を持つようになってきた。デザイン学は1960年代以降、認知科学、記号論、科学技術社会論（Science, Technology and Society：STS）のような様々な学術領域の知見を取り込みながら発展してきた。その中で例えば、必ずしも実用的に役に立つものを作るだけではなく、直接的には役に立たずとも、その人工物を通して未来の社会像についての議論を引き起こすことを目的としたクリティカル・デザイン/スペキュラティブ・デザインや、作られた人工物そのものを最終的な知の貢献とするよりも、それを作る過程や使われる過程で得られた知見を共有することに主眼をおいたResearch through Design（RtD）のように、客観的かつ再現可能な証拠のみを材料とするのではなく、研究者やユーザー（あるいは共同参加者）の主観的表現を積極的に用いる、実証主義的な科学と異なる研究の方法論を確立しつつある。

特にHuman-Computer Interaction（HCI）のような、電子計算機と人間の関わり方を探求する学問分野は、音楽のためのコンピューターを用いたシステムとインターフェースを研究するNew Interfaces for Musical Expression(NIME)のような新しい研究分野を生み出してきたが、その理論的基盤は科学（Science）のように私たちの世界の仕組みを解明、理解するための営みとは異なることもあり、RtDのようなデザインリサーチの系譜に位置付ける動きが活発になっている。本研究はそのような流れの上で、音楽のためのプログラミング言語の設計と実装の実践的経験と、音楽に関わるテクノロジーやメディアとしてのコンピューターの歴史にまつわる言説の批判的検討を通じて、音楽のテクノロジーの関わり方の異なる現在（Alternative Presents）やありえるかもしれない未来（Speculative Futures）[@Auger2010]を描き出すことを試みるものとなる。

本研究のアプローチは、近年のデザインリサーチの方法論の中でも2つの特徴的な点を持っている。まず1つは、アーティストや音楽家のような表現を行う主体自身が、通常所与のものとされているテクノロジー（例えば本研究では、プログラミング言語）の仕組みを自分で作ってみることで理解する、**技術的なブラックボックスを開くアプローチ**である。この、ブラックボックスを開くという言い回しは特に科学技術社会論において1980年代以降とりわけ用いられてきたもので、高度に積み重ねられ分析することが不可能になっていく科学の知の体系の成立過程を、研究室におけるフィールドワーク（いわゆるラボラトリー研究）や参与観察を通じて明らかにするという意味合いで用いられてきているが、本研究におけるブラックボックスを開くとはむしろ、元々非専門家であるアーティストや音楽家がDIY的に、通常とは異なる目的で技術の根幹的部分に分け入っていく、観察者というよりも、自らが技術者になってしまうことでその中身を理解するという意味合いで用いている。このアプローチは技術者やデザイナーの視点から見ると、デザインにおける想定されたユーザーのための道具作り、ユーザー中心的デザイン（UCD:User-Centered Design）の批判的継承として位置付けられる。ユーザーフレンドリーな道具というのは、裏を返せばユーザーを受動的消費者にするデザインでもある。通常、既に使える道具として与えられているものを改めて作るという行為は、科学や工学においては車輪の再発明や、DRY（Don't Repeat Yourself）の原則のような言葉で避けられているが、学習のために自らの身体を用いて道具の仕組みを理解することは必ずしも無駄なこととは言えない。それだけでなく既に固定化されてしまったテクノロジーの異なる姿を想像するための手がかりとなることもある。例えば城一裕らによる「車輪の再発明プロジェクト」では、レコードや写植、スピーカーのような単純な仕組みで作動するメディア技術を、デジタルファブリケーションの普及などにより、個人で利用できる技術環境が変容した中で改めて別の形で作り直すことで、紙の上にカッティングプロッターで溝を刻んだレコード、写植の文字盤を多光源プロジェクションのスクリーンとして利用する技法、耳を磁石で挟み込みコイルを近づけることで骨伝導を介して音を聴く《超超短距離電信装置》のように異なるメディア環境の可能性を想像させる道具を生み出している[@Jo2016]。

もうひとつの特徴的な点は、技術やメディアの歴史観の批判的再構築である。ミシェル・フーコーの「言葉と物」や「知の考古学」以降の、歴史が絶対的事実の積み重ねではなく、特定の誰かが記述することによって社会的に構築されていくことを前提とした価値観の中では、異なる技術環境を想像することはこれまでと異なる視点で技術とメディアの歴史を見つめ直すことに他ならない。こうした視点の代表的アプローチとして、フータモやパリッカのようなメディア研究者を中心に議論されている**メディア考古学**[@Huutamo2013,@Parikka2015]と呼ばれる、淘汰されたメディア装置を足がかりに異なる技術の歴史の可能性を示唆する研究群が挙げられ、「車輪の再発明プロジェクト」はメディア考古学とスペキュラティブ・デザインのアプローチとを接続したものでもある。

技術を形づくる主体がその内容を深く理解し、また同時にその使われ方への批判的視座を持つということは技術を作る個人の政治性に自覚的になることでもある。テクノロジーが社会の変化に大きな影響を与えうることが当たり前になりつつある現代において、安定したパラダイムの中で政治的に中立的に見えるパズルを解くだけのような技術研究[^puzzlesolving]はもはや成立しない。だからこそ、誰が誰のために技術を形作るのかという視点でのオルタナティブな工学のかたちを追求する必要がある。

[^puzzlesolving]: パラダイムという言葉を普及させたトーマス・クーンの「科学革命の構造」では、ある安定したパラダイム（特定の科学的領域をささえる認識の共有された構造[@Fukushima2021]）の中での科学的研究（通常科学）はパズルを解くような物と表現される[@Kuhn1971,p30]。

ここに、音楽土木工学という学問の命名理由のもう一つの理由、土木工学という分野の英語における表現、Civil Engineeringという言葉の選択がある。このCivil Enginneringという語は、現在では概ね日本語における土木工学と重なる領域を指してはいるものの、元々はEngineerが軍事的な技術に関わる者という意味合いを持っていたのと対比して用いられるようになったものだ[^civil]。

[^civil]: Civil Engineerという語は一般的に、1750年ごろにイギリスの工学者ジョン・スミートンが自らの専門を、相容れない軍事的な研究と区別するために名乗り始めたことが起源とされている[@Florman1988]。

つまり、音楽土木工学とは音楽とテクノロジーという都市における土と木に相当する要素を考える学問であると同時に、音楽のための市民工学という意味合いを持つ。この両面のアナロジーは、筆者が学んだSchool for Poetic Computationを立ち上げた人物の1人、アーティスト/アクティビストのテユン・チェの「Open Circuit, Open City」というタイトルの文章からインスパイアされたものだ[@Taeyoon2016]。

チェはSFPCでの授業を始め様々な場所で、自らロジックICを組み合わせてシンプルなコンピューターをDIY的に作る「Handmade Computer」のプロジェクト（[@fig:taeyoon]）や、餃子を作る工程を複数人で分担し、その作業分担の方法を変えることを通じてコンピューターにおける逐次処理・並列処理の違いを体感的に学ぶような「CPU Dumpling」と呼ばれるワークショップを行ってきた。その中でテユンは次のように述べている（以下、引用は全て筆者による訳）。

> *コンピューターを手作りすることで、はんだ付けや配線を繰り返す中でたくさんのことを考える時間を得た。コンピューターがどのように進化してきたかを知ることで、歴史に対する理解がより深まった。同時に、何が最近になってようやく可能になったのかを学ぶことで、オルタナティブな過去、そしてそれが照らし出すオルタナティブな現在とオルタナティブな未来という、テクノロジーとの異なる関係性を想像するインスピレーションを得られた。*

> *都市はよく、コンピュータと似て、ブラックボックスの中に封じ込められ、暗号化され、抽象化される。都市の住民は、空間がどう作られ使われるかを限られた範囲でしか制御できないし、私的に保有される公共空間もその意味でまたブラックボックスである。基礎的な部品からわたしたち自身のコンピュータをゼロから作ることで、〔自己を〕回復するためのオルタナティブな都市空間の創造を想像できはしないだろうか？*

> *都市は、コンピュータと似て、美学的熟考のための中立的対象ではない。そうではなく、競合し合う政治性と、危うくて不安定〔precarious〕な生活とが置かれた場なのだ。*

![テユン・チェによるHandmade Computerプロジェクトのひとつ、4 BIT FSM(Finite State Machine)[@Taeyoon2015]。](img/taeyoon_handmade.jpg){#fig:taeyoon width=70%}

ともするとこれらのプロジェクトはいわゆるシチズンサイエンスにおける、科学実験の体験教室と同じような、馴染みのない科学的作業を身近にすることを目指したものと大差ないように思えるかもしれない。かといって、ここで作られた原始的な電子計算機はその機能性や仕組み自体がこれまでの電子計算機に対するオルタナティブなものというわけでもなければ、芸術作品として計算機の見た目に美的価値を付加しようとしているのでもない。

テユンが行っているのはむしろ、自らが作ったり（DIY）、誰かと一緒に作ったりする（DIWO：Do it with Others）過程で、そもそもテクノロジーとは誰が誰のために形作るものなのかという問いを投げかける行為だ。こうしたプロジェクトは、スペキュラティブ・デザインのような、テクノロジーのあるべき未来の姿についての議論を巻き起こすことを目的とした人工物のデザインともまた少し態度が異なる。それは、作家自らが科学的技術を実践するか否かという点である。スペキュラティブ・デザインを提唱したダンとレイビーが、デザインと科学の付き合い方の分類に関して、 "Design about Science（科学研究から生じる問題や影響について、デザインを通じて考察する）"というアプローチに着目していたのに対して、テユンのようなアプローチに当てはまるのは "Design through Science(デザイナーが多少たりとも科学を実践する)"という態度である[^speculate]。デザイナー自身が科学技術の実践者になるという事はすなわち、技術者の身体的感覚に結び付けられており、言語かできる以前の状態に留まっている知識をデザイナー自らが身につけるということになる。この時、デザイナーや人類学者が科学技術研究者を観察したり、デザイナーと科学者がコラボレーションするだけでは取り出すことが敵わなかった、新しい伝達可能な知（Communicable Knowledge）を見つける可能性が立ち上がってくる[^communicable]。

本研究のアプローチは、プログラミング言語やコンピューターそのものの設計や実装のような、一般的には音楽や芸術表現と無関係なものと思われている事柄に自ら取り組み、その技術を理解することによって初めて得られる視点をデザイナー/アーティストの批評的視点と接続することによって、これまで共有されてこなかった技術者に埋め込まれた知を一度取り出し、さらに異なる方向性を見出す、いわば**Research through Design through Science(Technology)**とでも呼ぶべき態度である。

[^speculate]: [@Dunne2015,p208]。この他に "Design for Science（科学研究を伝えたり、わかりやすく説明したりするためにデザインを用いる）"、 "Design with Science（デザイナーと科学の真のコラボレーション）"という2つの関わり方が挙げられている。

[^communicable]:Research through Designという言葉が作られるきっかけとなった、クリストファー・フレイリングの "Research in Art and Design"では、アートやデザインの領域における研究行為をinto（歴史研究など、一般に「研究」と認識されているもの）、through（アクションリサーチや材料研究）、for（アーティストやデザイナーが自らの制作のために行う個人的な探求）という3つの接続詞で分類し、このうち "for"は伝達可能な知を生み出すことを一義的な目的としておらず、その知は制作者やあるいは作られた人工物に埋め込まれる（Embodied）とされている[@Frayling1993]。詳しくは第2章を参照。

# なぜプログラミング言語なのか

<!-- 3章のメタメディアの内容に対応する -->

では、音楽におけるコンピューターの利用のされ方を再デザインするための試みとして、なぜ音楽のためのプログラミング言語を作ることが役に立つのだろうか。それは音楽のためのプログラミング言語の構造を知ることが我々の音楽に対する認識–平たく（かつ大仰に）言えば、私たちにとって今日の音楽とは一体なんなのかという疑問を理解することにつながるからだ。

音楽のためのプログラミング言語が一般的に多くのアーティストにとっては、使うことならともかく、言語自体の設計や実装に至っては技術的に高度すぎて理解することが困難であることも、ひとつ重要な点ではある。しかし、音楽プログラミング言語に限らずとも大抵の音楽制作ソフトウェアや、その中で使われるプラグイン、あるいは電子楽器などが技術的にどう作られているかはやはりほとんどの場合においてブラックボックスである。こうしたツール群と音楽のためのプログラミング言語とで何が異なるのかといえば、当然、音楽プログラミング言語が言語であることである。

プログラミング言語はコンピューターという機械に対する命令を記述するものなのだから、あたかも自然言語のように扱うのは不自然に思えるかもしれない。しかし、コンピューターに対する命令は最終的に0/1の羅列である機械語として記述されるのだから、もし人間が0/1の羅列だけでコンピューターに対する命令をスラスラと記述できるのであればはじめからプログラミング言語などは必要ない。そういう意味では、人間が理解可能な形で記述されたテキストデータを機械語へと翻訳することで動作するプログラミング言語というシステムは、根本的には徹頭徹尾人間のための道具であり言語である。そして、プログラミング言語とは人間が思考し記述したモデルを計算機上で実際に動作させることができる道具だが、これは裏を返すと、計算機が理論上どんなに万能の装置であったとしても、人間が記述できない概念をコンピュータープログラムとして動作させることは敵わないということになる。

この万能性と言語による制約という矛盾めいた状況は、トール・マグヌッソンによってコンピューターを用いた楽器の特徴を**認識論的道具**と呼んだことに対応する[@Magnusson2009]。

本研究はマグヌッソンの議論を引き継ぎ、より焦点を音楽のためのプログラミング言語における、音楽のための最小限の抽象化とは一体なんなのかという問いをmimiumという言語の実装を通じて検討する。今日既存の音楽のためのプログラミングシステムや、それらを用いることで実現される様々な音声合成の手法は依然多くが現実世界のメタファー（楽譜や楽器、モジュラーシンセサイザーなど）に依存している。それ自体はマグヌッソンの指摘した原理的限界とも言えるものだが、問題はその具体的メタファーの部分はプログラムの意味論としてはじめから言語に組み込みのものとされており、現実的にはC++のような汎用プログラミング言語で記述されることだ。これは実用的な問題としては、各プログラミング言語ごとにそれぞれの言語が考える（とはいえ現実的には粒度の粗い） "最小限"が多数存在していることで、言語ごとの相互利用がままならないという問題につながる。しかしより根本的な問題として挙げられるのが、具体的メタファーに基づいた言語仕様が存在していることで、コンピューターをメディア装置として使う際の随一の特徴である、自らの機能をプログラミングという手段を用いることで変化、拡張させられるという**メタメディア**としての機能に限界が生じてしまうことだ。

メタメディアの思想の源流であり、今日のGUIを中心としたパーソナルコンピューティングの姿に大きく影響を与えたアラン・ケイとアデル・ゴールドバーグによるDynabookの研究では、コンピューターを使う人が自身でプログラムを書くことによって、自らの道具（ソフトウェア）の機能を自らに合わせて拡張させることが思想の根幹に置かれていた。だが、今日プログラミングという行為の裾野は随分広がったとはいえ、音楽を作るためのソフトウェアの機能をプログラミングを用いて自ら拡張できるような環境は、Ableton社のLiveにおける、音楽プログラミング環境Maxを内部拡張として用いることができるMax for Live、独自のスクリプト言語を使用できるReaperのような数少ないソフトウェアを除けば、未だメインストリームとは程遠いと言える。この自己拡張性の少なさは時に、想像できないことはプログラムとして記述のしようがないという限界にとどまらず、実現したいと思っている機能があるにもかかわらず（そして、プログラミングの知識があったとしても）容易に拡張することが難しいという状況を生んでいる。

つまりプログラミング言語についての理解を深めるということは特に音楽という分野においては、我々が音楽の認識を形作る仕組みを理解することでもあり、同時に社会の中における音楽を作るための道具が人間にもたらす自由と制約の仕組みを理解するという2種類の疑問にアクセスすることになる。
（もうちょっと補足してもいいかも）

# 本論文の貢献

（順番を整理したほうがいいかもしれない）

本論文を通じて学術的に貢献する内容は、大きく分けて3つである。

1つは、"音楽のためのプログラミング言語とは何か？"という、PLfMの存在論の提示だ。PLfMは歴史的にコンピューターを用いて音楽を生成するための技術としてスタートしつつも汎用プログラミング言語の理論を取り込んで発展してきたことにより、一重に音楽のためのプログラミング言語/環境といってもその応用範囲や想定される使用方法、さらに内部の実装方法までが多岐に及び、単純な比較をすることが難しい。また、評価のための語彙も "表現力が高い" "効率的" "汎用的"などの言葉が共通認識の無いまま慣例的に使われており、実際に何を意味するかもはっきりしないことがある。本稿ではまず音楽プログラミング言語の歴史的変遷を改めて整理した上で、"PLfMにはどんな種類があるのか"、"PLfMの特性はどう記述できるか"といった概念を整理して提示する。

2つ目は、"音楽のためのプログラミング言語を音楽を設計するという行為とは何か？"という問いである。録音技術（音響再生産技術）に端を欲した音楽のフォーマットは現在空間音響技術のためのフォーマットの普及などよって、原音再現という従来の明確な一つの目標を失いつつあるだけでなく、新しさを謳いながら一方でインフラストラクチャの性質による音楽の形式を画一化する傾向を持っている。その環境でコンピュータ上の表現の自由度を最大限担保するためにはプログラミング言語そのものを音楽のためのフォーマットすることが必要になってくる。この背景から、音楽プログラミング言語を設計することは2020年代以降における、テクノロジーを主体的に使う音楽実践の1つのあり方に位置付けることを試みる。さらにこれは、デザイン学におけるデザイン実践を通した研究の領域の広がる中で、社会構造自体を長い時間をかけて変化させていくことを試みる動きとも呼応する。これまでデザインリサーチ的手法はHumam-Computer Interactionの研究法の1つとして狭い意味で音楽プログラミング言語にも適用されてきたが、本研究ではプログラミング言語設計という行為をさらに一般化し、音楽土木工学という、誰もがアクセス可能な音楽のためのテクノロジーの変革のための政治的行動という広い領域へ接続する。

3つ目は、筆者が設計/実装した自己拡張性の高い音楽プログラミング言語"mimium"についての設計思想とその具体的な実装を提示した上で、以上2つの観点からの位置付けを試みることだ。mimiumは先述した音楽のためのプログラミング言語の歴史を見直し、汎用プログラミング言語の設計の上に最低限の音楽のために特化した言語機能を備える構造を取ることで音楽のための言語におけるブラックボックスを減らしながらもその実装の単純さと自己拡張性の高さを同時に実現できるように設計されている。


# 構成

![本書で提示する音楽プログラミングの歴史の概要。](img/thesis_structure.pdf){#fig:structure width=100%}


第2章以降は以下のような構成で論じる。本論文全体の構造を[@fig:structure]に示した。全体としては、2~4章で1960年代から2020年までの歴史をデザインリサーチ、メディアとしてのコンピューター、音楽のためのプログラミング言語というそれぞれの視点から振り返る。これらの歴史は例えばデザインリサーチとデザインであれば70年代以降のコンピューターを用いた機器のインタラクションデザインという点で重なりはするものの、概ね独立して読めるような構成にはなっている。第5章は通時的な視点でのPLfMの整理、第6章は実際の言語設計と実装についての解説、第7章はその実装の問題点を起点にした省察である。なお、第2章から4章にかけての歴史的文脈の整理は必ずしもmimiumという言語制作の背景として事前に定まっていたものではないことに注意してもらう必要がある。第2章で詳しく説明するように本研究の特徴的な点は実践を通じて、これまでとは異なる視点での歴史記述を行うことにあるからだ。

第2章では、まず音楽のためにコンピューティング技術の基礎的要素を再考するという筆者の研究の立脚点をデザインの歴史から説明する。コンピューター上で動作するシステムやインターフェースを作るということは、何か特定の課題が存在し、それを解決するための道具を作り、その効果を測定するといった工学的な視点で捉えられ、実施されてきた。しかしながらこれらの歴史には同時に、コンピューター以前に始まっていた工業製品のデザインにおける科学的手法と、その合理化に伴う功利主義やデザイナーの主体性の欠如といった批判といった文脈と接続され、近年ではヒューマン・コンピューター・インタラクション（HCI）分野においても、研究領域として、科学と異なる方法論としてのデザインリサーチの文脈が立ち上がりつつある。その中にはシステムや人工物を創造する過程の中ではじめて問題が立ち上がり、それを知見として共有することを目指したデザイン実践を通じた研究（Research through Design:Rtd）のような文脈や、デザインしたものを直接プロダクトとして利用するのではなく、その人工物を通じて未来の技術環境やあり得るかもしれない別の社会の姿の想像力を喚起し、議論を引き起こすことを目的としたクリティカル・デザイン、スペキュラティブ・デザインと呼ばれる試みがある。第2章では本研究で目指す、プログラミング言語の実装という実践的経験を通して、音楽とテクノロジーに対する個人の関わり方の異なる可能性（＝音楽土木工学という新しい学問領域）を提起する行為をこうした文脈上に接続する。

第3章では、メタメディア装置としてのコンピューターの思想の当初の理想とその現状について、エマーソンの「Reading Writing Interfaces」[@Emerson2014]を参照しつつ、ユーザーが真っ当にソフトウェアを作ることで音楽表現を行うことが難しい状況が、テクノロジーを積極的に用いる芸術家のアプローチを、ベンディング（≒技術の誤用）的アプローチへと近づけたことを示す。その上で、2000年代までは機能していたサーキットベンディングやグリッチのようなアマチュアリズムを伴う意図的な技術の誤用は今日のソフトウェア中心の音楽技術文化の中ではもはや機能せず、技術を深く理解した上で、コンピューターというブラックボックスを自らの手で開いていくようなアプローチへと転換を迫られている。これは結果的に2章で議論するデザインの運動とも並列しており、そのブラックボックスの開き方の具体例を音楽に限らないデザイナーやアーティストの取り組みから比較することで、ブラックボックス性の少ない、インフラストラクチャとしてのPLfMの設計を広義の音楽実践として位置付けることを試みる。

第4章ではより具体的な例を挙げつつ、PLfMの歴史を整理し、現在設計すべき言語の方針についての示唆を得ることを目指す。ここでは既存のコンピューター音楽のためのプログラミング環境についての文献を参照しつつも、より個々の言語のインフラストラクチャとしての役割に焦点を当てる。また本研究ではジョージナ・ボーンの80年代におけるIRCAMにおける作曲家と技術者の関わりを描いたエスノグラフィや、田中による80年代を中心に発生した、初期パーソナルコンピューターやその後のゲーム機における音声合成ICを活用した音楽表現であるチップチューン史を参照することで、より制度化（Institutionalized）、もしくは権威づけされたコンピューター音楽と、これまでコンピューター音楽の歴史に含まれることは比較的少なかったチップチューンのような、いわば傍流のコンピューター音楽を意図的に対比することで、より広い意味での（すでに用いた言葉を再利用するなら "弱い"コンピューター音楽の）歴史観を提示することでPLfMの定義をより明確にする。

第5章ではPLfMの現代における特性や概念を通時的な視点で整理する。そのために、PLfMの実装の方法の違いをドメイン固有言語のデザインパターン、汎用プログラミング言語における評価語彙の研究を参照しつつ、PLfMを使用するプロセスをHuman-in-the-Loopモデルとして提示し、ランタイムのブラックボックスを大きくすれば動的変更に強くなる、小さくすれば表現自体の汎用性が高まる、動的変更と汎用性を両立しようとすると設計が複雑化し実装のコストが嵩むといった根本的トレードオフが存在することを提示する。

第6章では筆者が設計した音楽のためのプログラミング言語mimium[@Matsuura2021]の詳細を記述する。まず第2〜4章で示してきた背景を総括し、1.ブラックボックスを可能な限り減らす,2.新しい表現を生むことを目的としない, 3.インフラストラクチャとしてのプログラミング言語の必要性という3つの設計方針を示す。mimiumは型推論を伴う静的型付け言語であり、汎用の関数型プログラミング言語の設計や実装に、音楽のための言語仕様を2つ、最小限追加する形で実装されていることが大きな特徴である。1つは関数の実行のスケジューリングを行う$@$演算子、もう1つは内部状態を伴う信号処理を通常の関数と同じよう記述可能な、状態付き関数の記法である。mimiumはこの2種類の記法を持つことで、これまではブラックボックスとして与えられていた基本的処理の単位をライブラリとして(実行性能を損なわないまま)実装可能であることを、既存の言語との比較を交えて示す。

第7章では、第2~6章で焦点を絞りながら説明してきた背景を、mimiumの現状における実装の問題点を基点に各章ごとの話題において振り返る——すなわち、PLfMの設計上存在するトレードオフの選択、PLfMの歴史におけるmimiumの位置付け、音楽実践の1つとしてのプログラミング言語実装、RtDとしてのPLfM設計、という順番で視点を広げていきながら制作を分析する。この中でPLfM制作においてブラックボックスの少ない言語を作る方針を突き詰めると、ホスト言語の実装とその上でのライブラリ構築という2種類の作業へ分岐する。そのため、結果的にホスト言語の実装には音楽に関わる作業が少なくなるという分断が発生してしまうという矛盾について説明する。

最終章では、前半で示したPLfMの存在論、歴史と後半で示したmimiumの実装とその実装過程の分析をより一般化し、音楽とテクノロジーの狭間で行われる非常に個人的な動機からの問題設定を基に始めたもの道具づくりを、多くの人間が共有して使うものへと開いていく研究領域を「音楽土木工学」として、近年の音楽情報処理研究との対比や計算機科学の動向交えて検討する。今後の研究課題として、音楽という応用領域の中では背景化されてきたオペレーティングシステムやコンピューターアーキテクチャといった計算機の根幹に関わる理論自体の見直しを行うことで、mimiumの実装に伴って明らかになった問題の解決の糸口になることを示す。