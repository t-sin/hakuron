<!-- 第7章 議論-->
# 序言

前章では設計した音楽プログラミング言語mimiumの仕様と特徴を例示してきた。

mimiumはラムダ計算ベースの汎用プログラミング言語の設計、実装の上に最低限の音楽向けの機能ー論理時間ベースのスケジューラと`delay`や`self`を用いた時間方向の参照による表現をという大きく分けて2つの機能を足すことで、汎用プログラミング言語の自己拡張性を失うことなくブラックボックス的構造によるアクセス不可能性を可能な限り排すことを目指した。

本章では前半、言語の実装において未だ不十分である機能の分析を通し、その過程をプログラミング言語に限らない、音楽におけるコンピューターの使い方全般の議論に一般化することを試みる。後半は、2〜5章でそれぞれ大きな文脈から焦点を絞る形で行ってきた音楽プログラミング言語研究の文脈の構築を、今度は**逆順で**、焦点を広げていく形でそれぞれの章ごとの話題についてmimium設計、実装を通じた貢献を改めて振り返る。つまり音楽プログラミング言語設計における実装の方針と特性のトレードオフという選択の中でのmimiumの設計の選択（あるいは、非選択）、歴史的な観点でみた音楽インフラストラクチャとしてのプログラミング言語設計の位置付け、デザイン実践を通じた研究(RtD)としてのプログラミング言語設計の学術的貢献、2020年代においてコンピューターを積極的に使う音楽家の実践のあり方、という順番になる。


# 現状の実装の問題点

まず、現状mimiumを実用的に利用する際に3つの問題点が残っており、これらについて解説する。1つは離散的なイベントの記述は命令型、信号処理は関数型のパラダイムという2つの記法のミスマッチ、2つ目は信号処理に用いる状態付き関数をパラメトリックに複製できないこと、最後がFFTに代表されるサンプルをあるまとまった数ごとに処理をする信号処理が記述できないことだ。

## 離散イベントの処理と信号処理の記述のミスマッチ

`@`演算子を用いて関数実行を時間指定するという方式は、当然ながら即時その関数が実行されないために、返り値を持たないvoid型の関数を用いて副作用（変数の破壊的代入もしくは標準出力への書き込みなどのIO操作）を起こす、命令型プログラミングのスタイルに帰着する。これはmimiumにおける信号処理で行われる、返り値を次の関数の引数として渡していくことで、信号フローの表現を行うようなスタイルとは大きく異なる。

シンタックス上は[@lst:frp]のように、継時再帰とクロージャを組み合わせれば、離散的な値の変化を連続的な信号処理のスタイルと同様に表現することができる。だが、現在の実装ではこのコードは実現不可能である。mimiumの現在の実装では関数内部で定義されたローカル変数は本来のスコープを超えて生存することができないため、変数の参照を返り値として返却するようなこのコードを実行することができないためである。コンパイラが仮にライフタイム解析[@Ruggieri1988]などの静的解析を用いてコンパイル時に変数の寿命を決定（あるいは、プログラム実行中は永続的に解放されないことを静的に判定）できればこの時間方向に離散的なタイミングで変化する数値の抽象化が可能になる。


\begin{lstlisting}[float,floatplacement=H,label=lst:frp,language=Rust,caption=Example of encapsulating a temporal discrete value not realized in current implementation of \mimium{}.]
fn frp_constructor(period){
	n = 0
	modifier = |x|{
		n = x //capture freevar
    modifier(n+1)@(now+period)
	}
	modifier(0)@0
	get = ||{ n }
	return get
}
val = frp_constructor(1000)
event_val = val()
\end{lstlisting}


## 状態付き変数のパラメトリックな複製

もう1つの問題は、現在の実装では`self`や`delay`を用いる状態付きの関数をパラメトリックに複製できないということだ。[@lst:filterbank]のような例を考えてみよう。関数`filterbank`は引数`N`の条件を基にして、別の引数として与えられる`filter`関数を再帰的に足し合わせるようなコードだ。この時、`filter`関数に用いられる状態変数の数と、そのためのメモリのサイズはコンパイル時に静的に決定されねばならない。しかしfilter関数が何回複製されるかは引数である`N`によって決定されるために、`filterbank`関数が実行されるタイミングになるまで状態変数の数の決定は不可能である。

\begin{lstlisting}[float,floatplacement=H,label=lst:filterbank,language=Rust,caption=Example of parametric replication of signal processor that cannot be realized in current implementation of \mimium{}.]
fn filterbank(N,input,lowestfreq, margin,Q,filter){
	if(N>0){
		return filter(input,lowestfreq+N*margin,Q)
				+  filterbank(N-1,input, lowestfreq,margin,Q,filter)
	}else{
		return 0
	}}
\end{lstlisting}


このようなパラメトリックな信号処理プロセッサの複製は、たとえばFaustではパターンマッチを用いたコンパイル時再帰によって記述可能である。これはオリジナルのFaustのセマンティクスの中には存在しなかった機能で、Gräfによる項書き換えシステム—パターンに応じてコードそのものをコンパイル前に書き換えてしまう一種のマクロの導入によって解決されたものである[@Graf2010]。それ故、コンパイル時に[@lst:filterbank]でいう`N`に相当する、コンパイル時に展開される変数が、整数の定数であることを保証できない場合にはコンパイルエラーになる。加えて、FaustのBlock-diagram Algebraの意味論とマクロの体系は別物として存在しているため、コードを書いている人からすると、コンパイル時定数と実行時に変化する変数はどちらも同じ数値であり区別がつけづらい。

mimiumにおいてこの問題を解決するためには、コンパイラが定数を予め展開してしまうような仕組み、あるいはマクロを最低でも状態変数の解析の前のステップに導入する必要がある。これはコンパイラが暗黙的に行うことでも解決は可能だが、Faust同様、ユーザーからすれば`N`が定数でなければいけないことは意味論の外側の事情になってしまうので理解が複雑になってしまう。

この問題は一歩引いて考えると、そもそもこの`filterbank`関数は、シグナルフローをコンパイル時に決定する処理の記述と、実際にプログラムが実行されるタイミングで発生する信号処理という、2つの時間における計算を混在させていることになる。こうした状況はMetaMLに代表される一種の多段階計算[@Taha1997]と類似した状況と考えられる。多段階計算は、計算が起きるステップを明示的に文法の中に記述でき、型システムにもその変数がいつ計算される変数かという情報を入れることができるような計算パラダイムで、再帰の発生する計算などを効率的にプログラムできるといった特徴がある。

計算がいつ発生するかという視点で考えれば音楽プログラミング言語には、シグナルフローの決定という計算以外にも例えば波形テーブルの生成、リズムパターンの生成といった、プログラムの中では一度きりしか発生しない計算はいくつもあるため、導入することで副次的に得られる利点もあると考えられる。

さらに、MacroML[@Ganz2001]のように、多段階計算を安全なマクロとして考えると、言語の自己反映性を高め、言語内DSLをライブラリとして実装できるような応用方法も考えられる。

例えば、Pucketteはサンプリング理論に対する不満、と名付けた論考の中で、連続領域で（例えば微分方程式などの形で）構築した楽器や電気回路の数学的モデルを離散化してから計算するような例を挙げ、すべての表現がサンプリング理論に基づく、各時刻における音圧に対応した数値を計算するような音楽表現には一定の限界があることを指摘している[@Puckette2015]。たしかに、プログラミング言語を使うということは、シンボルを組み合わせることである（ときには実在しないかもしれない）現象のモデルを記述し、それをコンピューターに実行させているということなのだから、例えばバネ–マス–ダンパといったシンボルを組み合わせてある力学系のモデルをテキストとして記述することは、モデルが連続領域であろうと離散領域であろうと可能だし、連続領域のモデルとして記述されたシンボルの組み合わせを離散化する関数に通し、信号処理に利用する、といった方法の記述は1つのソースコードの中に収めることも可能なはずだ(実際、Wolframのような数値計算のための言語ではまさにそのような記述が可能である[^wolfram])。これもやはり、モデルを離散化するという計算が大抵はコンパイルしたタイミングで発生しており、いつ計算するかの意味論が存在しないことにより、連続領域のモデル記述は一度離散化したデータを読み込むといったプロセスを経なければ記述ができないという見方ができるだろう。この考え方をもう少し進めれば、例えば微分方程式のモデルを記述する、という作業を機械学習におけるモデル学習のための関数を記述する、という置き換えもできる。もちろん、現実的には機械学習のようなモデル学習に計算リソースを激しく使うようなケースでは、コードを実行するたびに学習し直しということになっては非効率極まりないので、計算した結果をキャッシュするような仕組みがコンパイラに必要になるだろうが。

言い方を変えると、Wavファイルによるサンプルやウェーブテーブルも、連続領域モデルを離散化した後の重みづけパラメーターのような計算結果も、機械学習における学習語のモデルデータも、**何かしらのモデルから生成されたキャッシュ**のようなものと捉えることもできるだろう。この、いつ計算するかを意味論に明示的に加えていくことは、現在の音楽情報処理において解離してしまっている、pythonを用いて学習、Maxなどのツールを用いてモデルを実行し音声をリアルタイムで出力といったような2つの作業を1つながりの作業としてつなぎ合わせるような役割を音楽プログラミング言語に与えることに繋がる。

[^wolfram]: https://reference.wolfram.com/language/howto/SolveADifferentialEquation.html.ja?source=footer


## 複数サンプルレートが混在した信号処理

mimiumの信号処理は1サンプルごとの処理の記述によって表現されているため、高速フーリエ変換（FFT）に代表されるような、256、512などまとまった数のサンプルを処理し、同じまとまりのサンプルを一挙に出力する、いわゆる複数サンプルレートの混在した信号処理（Multi-rate Processing）の記述が不可能である。FFTは音声信号を時間領域から周波数領域へと一度変換し、なんらかの処理を経て再度時間領域へと逆変換を行う、スペクトラルプロセッシングと呼ばれる種類の今日多用されている信号処理に必須の処理である[@Roads2000,どこかの章]。この問題はサンプルごとの処理を基本とする言語であるFaustにも共通した問題であり、実現のための文法拡張は同様に試みられている[@jouvelot2011]ものの実用には至っていない。Kronosはサンプルレート自体を変更するコンパイラ組み込みの関数を導入することでこれを解決している[@Norilo2015,p40~41]。これも多段階計算同様に**いつ計算するか**に関わる、一般的なプログラミング言語では考慮されない要素であるため、どのみち意味論に何かしらの拡張を加えなければ根本的な解決はできないものと考えられる。

# より形式的な定義のための関連研究

現在のところ、mimiumの統語論の定義に関しては付録で示すように形式的な定義を行えてはいるが、意味論、特に、`self`のような状態付き関数の扱いは実装によって示されているのみである。この参考となる研究がmimiumを発表したACM SIGPLAN FARM(Functional Art, Research, Modeling)というワークショップで同じセッションで発表されたW計算（W-calculus、ラムダ計算と同じような名付け）である。W計算はFaustに強く影響を受けていながらも、Faustのように入出力を持ったブロックのグラフを組み合わせる構造ではなく、ラムダ計算をベースにした信号処理のための計算で、通常のラムダ計算に現れる項に加えて、$feed x.e$といった独自の項が追加されている。この`feed`はその項における1時刻前のサンプルでの計算結果が$x$として項の中で再帰的に利用できるといった意味合いをもち、これはmimiumにおける`self`の概念に直接的に対応する。例えば1サンプルずつ引数`incl`に応じて増加するカウンターの関数[@lst:wcalc]はW計算の中では次のように表せる。


\begin{lstlisting}[float,floatplacement=H,label=lst:wcalc,language=Rust,caption=1サンプルずつ増加するカウンター]
fn counter(incl:float){
    return self+incl
}
\end{lstlisting}

$$
\lambda \: incl.feed \: self.(incl+self)
$$

W計算はディレイのような、過去のサンプルを参照するような意味合いを定義すると、実用的には過去のサンプル全てを保存しなければならず無限のメモリを必要としてしまうという理想的形式化に伴う問題（例えばChronicがその典型である[@Brandt2002,pどこか]）に対しても都度意味論を拡張することで対応できている。また、OCamlで書かれたW計算で記述された信号処理のプログラムを、W計算のインタプリタとともに一度MetaOCaml上で評価することで、入力プログラムに特化したインタプリタプログラムを生成し、コンパイラの最適化をさらに組み合わせることでリアルタイムでの計算も実現できるようになっている、Multi-rate信号処理への拡張も既に方針が示されているなど、実用を意識した上での理論構築がなされている。

mimiumも根本的な意味論の定義をW計算の形式を借りることによって可能になるだろうと考えられる。もっとも、W計算においても時間方向に離散的な処理の意味論は含まれておらず、現状のランタイムとの通信という実装に依存する定義方法に対する解は今後別に検討する必要がある。

# 実装の方針とトレードオフの選択

次に、第5章で整理した、音楽プログラミング言語の実装の方針と、それに伴う特性のトレードオフがmimiumではどうなっていたかについて改めて整理しよう。

まず、実装の方針としては、自己反映性が高いホスト言語に乗る形でのInternal DSLとするか、文字列データの解析から行うExternal DSLとするか、あるいはそのハイブリッドの形にするかという視点があった。ここについてはmimiumは完全なExternal DSLとなっている。コンパイラ・コンパイラであるbisonを用いることで文字列解析の実装そのものはSuperColliderやFaust同様に下げられているが、C++という低レベルプログラミング言語での実装を行っているためその実装の手間（開発コスト）は少なくない。

よりテクニカルな問題としてC++を基盤としない言語を用いて開発し直すという選択肢も考えられる。具体的には、C++（17）を用いての実装において、実装の参考にしたOCamlと比べると代数データ型の扱いが複雑になることが大きな障害となった。C++17においては、標準ライブラリに`std::variant`という、代数データ型における直和型（N種類の型のうちどれか1種類が含まれているような状態を示す型）が利用できるようになったが、これはAbstract Syntax Treeを表現するための木構造に用いる再帰する代数データ型(新しく型を定義するときに自分自身の項が含まれるような型）の定義を少し遠回りな方法でなければ実現できないことによる[^recursivevariant]。加えて、N個のvariantの中から各データ型に対応する処理を記述する際、OCaml等の関数型言語においてはパターンマッチと呼ばれる記法を用いて短く処理を記述することができる。C++でvariantを使った場合、テンプレートによる静的ポリモーフィズムの複雑な記述を行う必要がありこれも開発の効率を落とす一つの要因であった。そもそもC++を開発言語として選択したのは、第5章で説明した通り音楽のための言語を実装するにあたって、メモリの確保を明示的に制御できるような言語である必要性があることを意識していたという理由があるが、これは今にして思えばランタイムの実装（C++で書かれたプログラムならコンパイルされそのプログラムは静的にメモリを確保して動く）とコンパイラの実装(何かしらの言語で書かれたプログラムがLLVMライブラリなどを通じて静的にメモリを確保するようなプログラムを動的に出力する)を混同していたため、コンパイラ部分だけの実装を別の言語で実装することは可能である。ただ、幅広いプラットフォームをサポートしようと思えばLLVMが利用できることは重要な要素であるため、公式でそれらがサポートされているOCamlや、C言語APIをラップしたライブラリが存在しているHaskellやRustのような言語が異なる実装のための候補として挙げられる。

[^recursivevariant]: `std::variant`の実装の元となったboostライブラリの中には再帰するvariantが記述可能なものもある。URLなどで補足する

ともあれ、mimiumにおける独自に新しくシンタックスの定義を行っているため、（その表面上の見た目であるシンタックスはRustという既存のポピュラーな言語に寄せてあるものの）Internal DSLとして実装されている言語と比べてるとその学習コストは高いし、ホスト言語の既存のライブラリ資源の活用も難しい。つまり、既存の音楽プログラミング言語の利用者からの参入障壁が大きい。これはインフラストラクチャとしての言語という側面から考えると重要な問題で、給水塔という既存のインフラストラクチャに乗ることで広がる携帯電話の基地局という新しいインフラストラクチャ[@Parks2015,p2]のように、新しいインフラストラクチャを整備するために既存のインフラストラクチャを利用することは必須とは言わずとも、利用しないことによってハードルが格段に上がってしまう。設計当初、言語自体の表現力が高くできてさえいればあまり問題にならないだろうと考えていたが現在はその考えは間違えだったと感じている。すでに繰り返し述べているように音楽プログラミング言語の実装には時間がかかる。言語自体の実装やアップデートもそうだし、言語上で構築するライブラリはなおのことである。なぜなら、言語上で開発されたライブラリは言語の中核的な機能や、includeのようなモジュール読み込みのための機能が更新されたり変更されるのに伴って大きく変更される必要がままあるため、本腰を入れて開発を始めることが難しいからである。そうしたときに、外部の言語のライブラリを活用できるということは、言語のコアな機能の更新をチェックしながらも実用性を失わずに存在し続けることができるということになる。

今後このような言語間の相互運用性を高めるための方法としては2つの方針が考えられる。1つは、別の言語の関数呼び出しの中で最も実装が簡単なC言語ライブラリの関数呼び出しを、mimium上でライブラリ名、関数名、型名を書けば実行時にリンクして呼び出せるようにする、いわゆるForeign Function Interface(FFI)の機能を追加することだ。ただ、簡単とはいえ、mimiumでは意味論上隠蔽されているハードウェア的な要素が含まれる型の扱い、つまりポインタ型の扱いを型システムのシンタックスにも追加しなければならないため、簡単とはいえコンパイラに入れる手間は比較的複雑なものとなる。

2つ目は、mimium自体をFaustのように、MaxやSuperColliderのUGenとして扱えるようなワークフローを整備することで他の言語の拡張機能的に使えるようにするという方法だ。Faustに限らずとも例えば現在は文字列から独自の構文解析を行う、典型的なExternal DSLであるSuperColliderもその元となった環境はPyriteというMaxのためのエクスターナルオブジェクトとして利用できるスクリプト言語だった[@McCartney2020]。これは既に、mimium自体のアーキテクチャをなるべく疎結合にしていたこともあり、アーキテクチャの図におけるオーディオドライバの部分に当たる箇所を、MaxやSuperColliderそれぞれのUGen作成のためのAPIを用いて実装すればよいため、C言語FFIの実装と比べると比較的簡単ではある。


(トレードオフの選択に関してもう少し詳細な記述をしたい)

# 歴史的観点

次に、第4章で検討した歴史的変遷におけるmimiumの位置付けを改めて考察しよう。音楽プログラミング言語は歴史的には、80年代以前はあらゆる種類の音楽制作ソフトウェアの起源としての意味合いが強く、90年代のSuperColliderやMax、Puredataのような、音楽のための最低限の抽象化を施すことで、音楽プログラミング言語を学ぶためにまずそれより低レベルな言語について学ぶような状況を避けつつ、表現は既存の音楽様式に縛られないような自由度を持つといったバランスをとった言語によってその意義が決定づけられたという流れがあったのだった。さらに2000年代は、既存の言語では組み込みのもの（＝UGen）として与えられていたものまでもプログラマブルにできるような、Faustに代表される低レイヤーの拡張、言語の意味論自体に自己反映性の限界があることに対して、既存の汎用言語の表現力を借りることによって突破するような高レイヤーの拡張、オペレーティングシステムに依存してしまう荒いタイミング制御をさらに正確にするような取り組みという3つの方向性が現れてきていた。

この中でmimiumは主に低レイヤーの拡張に重きを置きつつ、既存の言語では信号処理という、時間方向に連続した処理だけでなく、小規模なスケジューラを載せることにより離散的なイベントの実行も射程に入れている。既存の音楽の様式をなるべく言語仕様に埋め込まないようにするべく、汎用言語の設計に最低限の時間制御の言語仕様：関数の時間指定実行と、`self`や`delay`による信号処理における時間方向の参照による表現という2つの機能を載せつつ、かつメモリやスレッドのようなハードウェアを意識する必要はない（特定のハードウェアのアーキテクチャにロックインされない）ようなシンタックスというMcCartneyのいう "音楽のための最低限の抽象化" を現代の状況において可能な範囲で再検討したものだった。

一方であえて重視しなかった機能として、近年の高レイヤーの拡張を試みる言語が同時に行ってきたコードの動的変更、つまりライブコーディングのための工夫はほとんどされていない。とはいえ、全体のアーキテクチャの参考としたExtemporeは低レイヤーの表現の自由度を担保しながらライブコーディングができることを目指した言語であり、LLVMという低レイヤーの処理をメモリ上でコンパイルして即時動作させるインフラストラクチャを用いているという共通点を見れば、少し手を加えることで、動的にコードを変更していった時に音声がブツ切れにならないかといった細かい考慮を度外視すれば実現自体は可能だと考えられる。ただし、その機能はLLVMのJITコンパイルのためのライブラリに依存することになるため、LLVMを使わないバックエンド–具体的には、Webブラウザ向けのWebassemblyバックエンドなどを追加しようと思った時の移植性が低くなってしまうことが予想できる。現在はコードの動的変更のしやすさよりも稼働できるプラットフォームの幅の広さの方に重きを置くべきと考えている。

（この辺ももうちょっと充実させたい）

## 音楽プログラミング言語とは何か？

ここまでの視点で一度改めて本研究の提出する貢献のひとつ、音楽プログラミング言語の存在論についての議論を固めよう。

音楽プログラミング言語とは本質的にはMcCartneyの言ったように、音楽のための最低限の抽象化機構を備えた人工言語である。その最低限をどこに設定するかによって、大きければUnit Generatorのインタプリタのモデルのようになるし、小さければFaustのような形式的意味論を備える言語体系になる。

プログラミング言語とは現代においてはハードウェアの違いに依存しない抽象的な計算モデルを、人間が記述可能な形で操作できるようにしたものといった意味合いが強い。その中でも、比較的現代的なものを含めて汎用プログラミング言語の下敷きになっている理論は未だ可能な限り速く計算できることが是とされる時間を考慮しない計算モデルだ。また時間を織り交ぜた抽象計算モデルは、少なくともリアルタイムコンピューティング(線形時相論理)、並行計算(CSP、PI-Calculus)、論理時間に基づいた計算(Faust/W-calculus)全てが音楽の処理には現実的には必要でありながら、未だ確立したモデルが存在していない。

そのため、音楽プログラミング言語を汎用プログラミング言語の上にライブラリとして構築しようとしたとき、必要な時間の制御に関する機能や記述方法を、純粋に上のレイヤーに積み重ねて設計するようなことが難しくなる。それ故ホスト言語が本来扱うよりも低レイヤにある、実際のハードウェアに近い操作の記述を行う必要が出てくるという、純粋な抽象化のレイヤー構造が崩れる抽象化の逆転現象が発生する。

そのため、なるべく自由度の高い音楽の記述を行うにはライブラリではなく言語の設計そのものを行う必要があり、それは未だ確たるものが存在しない時間を考慮した抽象計算モデルの中で暫定的なものと、ハードウェアやOSと言ったシステム上で動くランタイムプログラムをどうにか連携させることで動かすというブリコラージュ的なプログラミング言語であるという表現ができるだろう。

# デザイン実践を通じた研究（RtD）として

さて、さらに視点を広げて本研究がデザイン実践を通じた研究（RtD）としてどのような位置付けができるのかについて検討しよう。

第2章前半で論じたように、プログラミング言語を設計する研究はその評価の基準の曖昧さの一方で、各技術要素については定量/定質様々な方法で客観性を持った評価をすることは可能だというHCIにおけるインターフェースデザインの主要な研究とはやや趣が異なる研究である。mimiumの設計も、第6章で論じてきた中心的な機能以外の部分に関しては実用性を考えた別個の機能が飛び飛びに開発されている。例えば本論の中では触れなかった、外部のファイルを読み込むincludeの機能などは音楽的に関わる意味論の設計の外側であったため、単純な文字列置き換えによる場当たり的実装となっている。一方でこの機能は開発されてなければ様々なコードのテストのファイルはライブラリのような機能分割をしない全て自己完結したコードでなければならない。

このような状態で、本論文の主要な主張(Claim)たる、音楽において自分のソフトウェアを自分で開発できるようなインフラストラクチャの形成という目標に対して、それを支える根拠（Evidence）は長期的目線での音楽情報インフラストラクチャの形成の必要性とそれに応じたなるべくブラックボックスを少なくするような言語の設計と実装という、いわば設計思想のみであって、個々の技術的要素、例えば、信号処理をLLVMを用いることでコードをメモリ上でコンパイルでき、リアルタイムで高速な処理が行える、といった要素は、例え厳密なベンチマークを行っていたとしても主張を支える十分な根拠とは現状なり得ない。mimiumという人工物に対するAnnotationとしてのこの主張と根拠の結びつきは、今後言語が少しづつ実用される中で初めて評価されることになる。



(やっぱり言い訳がましさが残る気もするので、もうちょっと言い回しを賢くしたい)


# テクノロジーを用いる音楽実践として

最後に、プログラミング言語設計自体を2020年代における1つの音楽的実践としてできるかについて検討しよう。

アマチュアリズム的態度に準じたハッキング/ティンカリング的態度に基づくテクノロジーの誤用はもはや、アクセス不可能なブラックボックスにより無効化され、コンピューターという象徴機械を介して音楽文化は無意識に画一的な方向に収束する傾向にある。

そうした時代に音楽家が取れる態度はまず、テクノロジーの中身そのものを根本的に理解できるようになっていくよう変わる必要があるし、音楽文化全体においてテクノロジーの理解を促すような教育も必要である。PucketteはMaxやPuredataが比較的普及した後でも、それを使うためには教育の要素が不可欠だと主張しているが、この状況は現在になっても変わっていないと言える。

> しかし、コンピュータハードウェアの低廉化によって交わされた約束に、私たちはまだ追いついていない。確かに、いまやすべての道具が入ったコンピュータを400ドル程度で購入でき、アンプとスピーカを追加すればコンピュータ音楽制作の準備が整う。しかしこれは、システムを構築し、フリーの良いソフト見つけてインストールし実行するために必要な知識があることを前提としている。コンピュータを数千ドルに、ソフトウェアを数千ドルにしたいという多くの商業的な関心が、私たちの前に立ちはだかる。
> コンピューティングとコンピュータ音楽の民主化に不可欠な要素は、地域の知識ベースを育成することだ。将来を見据えた音楽教育者は、学生が自分のコンピュータを構築するのを促すために何時間も割いている。自家製コンピュータと自家製コンピュータ音楽ソフトウェアの国際的な文化を、いつか見たいと私は思う。過去に裕福な西側はソフトウェアを開発し、何百万ものCDを作り、買う人には誰にでも販売した。将来的には、他の世界から輸入されたソフトウェアを研究し学習するセンターを見てみたい。
> 知識を育てるコミュニティが、特にLinuxのような非商用OSでは必要である。もしLinuxを使う友人がいなければ、動かすまでには障害があるだろう。しかし、世界の多くで少なくとも村の1人や2人に、コンピュータ音楽の専門知識（マシンの組み立て方法、OSのインストール方法、ソフトウェアの実行方法など）がある未来を想像できる。[@Puckette2002]

![分岐するテクノロジーに対して、テクノロジーの意図的誤用という方法論と、あり得たかもしれない現在へのけもの道を作るという本研究の立ち位置の違いを概念化した図。](./img/wildpath.png){#fig:wildpath width=100%}

さらに、テクノロジーを深いところまで理解した上で取れる態度は2つに分かれる。概念を[@fig:wildpath]として提示した。ひとつはテクノロジーの中身をわかった上で敢えて誤用することで、作られたテクノロジーの価値を転換する[@Tokui2021]という的態度だ。一方でこの態度には、音楽家という人間の外部にテクノロジーを置き、誰かが作ったテクノロジーの変革のタイミングに依存して音楽文化が変化していく、ThebergeのMultiSectorial Innovation的状況を受け入れた上で、即興的に反応して技術の異なる可能性を追求するということにもなる。これは近視眼的な意味でのテクノロジーとそれが生み出す新たな象徴による文化を形成するかもしれないが、Attaliの反復の系から抜け出せるほどの新しい音楽文化を作るには一歩足らない。

そうでないやり方として、ここ数年の人工知能の過熱のような論争中のテクノロジーではなく、論争後、例えばMIDIのようにすでに所与のものと決定づけられてしまい、透明な背景と化してしまったインフラストラクチャのような対象を、長い時間がかかるとしても自らの手で再発明し、あり得るかもしれない今（Alternative Present）を生み出すことが必要だ。そしてそれはデモンストレーションとして議論を巻き起こすところまで完結するのではなく、少しづつでも今作り始めて今使い始めてしまうという、技術の可能性の道の間に存在するフィールドにけもの道を作り出すようなアプローチである。

この態度の1つのインスタンスが、プログラミング言語開発という手段である。

## 音楽プログラミング言語を作るとはどういうことか

RtDとしての実践、音楽実践としてのプログラミング言語制作という話題のまとめとして、本研究の貢献のもうひとつ、音楽プログラミング言語を作るとはどういう行為なのか、についてまとめよう。

音楽プログラミング言語とを作るとはすなわち音楽のための最小限の抽象化機構を実装するということだ。これは大きなブラックボックスを持つUGenパラダイムの言語であれば、オシレーターやフィルターのようなプリミティブUGenを実装する作業も言語設計、実装の一部となる。しかしブラックボックスを小さくした言語ではオシレーターやフィルターの実装はその言語上で行うライブラリの実装作業となる。

<!-- 

![従来のMulti-Languageパラダイムに基づく言語におけるプログラミングの学習経験の差を "いびつな階段" として概念的に表した図。](img/Ladder.png){#fig:ladder1 width=90%}

![mimiumのようなブラックボックスを減らし、ライブラリとしての実装の役割を広げた言語における学習経験の差を "突然急になる坂" として概念的に表した図。](img/Ladder2.png){#fig:ladder2 width=90%} 

-->
\begin{figure}[htbp]
  \begin{minipage}{0.5\hsize}
    \begin{center}
        \includegraphics[keepaspectratio, width=1\hsize]{img/Ladder.png}
    \end{center}
    \caption{従来のMulti-Languageパラダイムに基づく言語におけるプログラミングの学習経験の差を "いびつな階段" として概念的に表した図。}
    \label{fig:ladder1}
  \end{minipage}
  \begin{minipage}{0.5\hsize}
    \begin{center}
        \includegraphics[keepaspectratio, width=1\hsize]{img/Ladder2.png}
    \end{center}
    \caption{mimiumのようなブラックボックスを減らし、ライブラリとしての実装の役割を広げた言語における学習経験の差を "突然急になる坂" として概念的に表した図。}
    \label{fig:ladder2}
  \end{minipage}
\end{figure}

こうしてなるべく音楽プログラミングにおける作業における経験の階段のギャップを減らし、パパートのいう天井は高く、床は低くといった目標を追求していくと、しかし最終的には肝心のホスト言語の実装そのものはほとんどテキストデータを読み込んでより抽象的なデータ構造へと変換していくデータ変換器と言った様相を呈してきて、階段のギャップはほとんど均一になったが最後の一段だけが飛び抜けて高い、といった切断を引き起こしてしまう矛盾が根本的に存在する。この現象を説明した図が[@fig:ladder1]と[@fig:ladder2]である。**いびつな階段モデル**：[@fig:ladder1]が各ドメインごとに使う言語を分ける、現状のMulti-Languageパラダイムに基づく言語の使用と開発においてそれぞれの経験の差が発生していることを概念的に表したものだ。なおScore-Orchestra-InstrumentはCSoundで用いられた用語だが、MaterialやAtomはあくまでメタファーとして独自に用いている。言うなればInstrumentというUGenをC言語などでプログラミングする作業がMaterialレベルのプログラム、さらにC言語のコンパイラそのものを作るような作業がAtomレベルのプログラムとでも言えよう。一方、**突然急になる坂モデル**[@fig:ladder2]がmimiumのようなブラックボックスを減らし、ライブラリとしての実装の役割を広げた言語に対応する。シーモア・パパートのいうプログラミング体験における天井と床、つまり高レベルの抽象化と低レイヤーへのアクセス可能性は広がっているし、各言語間に存在した差異もなだらかになっている一方、言語を作ることそのものの難易度はC言語などよりも理論的背景を多く必要とし難易度が高くなってしまう。

つまり、音楽プログラミング言語を作るという作業は最終的に "音楽のためのライブラリを作りやすい汎用言語を作る"と "その言語上でライブラリを作る"という2つの行為に分裂していく。

このトレードオフは根本的には解決しようがないが、多数ある言語同士の相互運用のしやすさを上げることである程度は解決できるものと思われる（もうちょっと補足）。


# 音楽土木工学という学問領域






<!-- 強いコンピューター音楽 : 作品のユニークネスにコンピューターを使用することが関わってくる
弱いコンピューター音楽 : 頑張ればコンピューターがなくても実現できるけど、コンピューターを使用することで製作/配布/再生/上演が円滑になる

**やや弱いコンピューター音楽: 作品を成立させるのにコンピューターが不可欠だが、コンピューターを使っていることは作品のユニークネスとは特に関係がない**

トフラーのプロシューマー、CGM、End User Programming -->

# 小括