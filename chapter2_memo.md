日常的行為の中に存在する、体系化されることのない様々な技法（method）に着目するエスノメソドロジーの分野の代表的研究者であるエリック・リビングストンは数学の証明プロセスや科学実験を自ら行うことによってその過程に存在する暗黙的なテクニックの存在を明らかにする研究を行っている[@Livingston1986]。エスノメソドロジーは通常その分析方法が会話分析という手法と結び付けられているが、西阪はリビングストンのような自ら実践することで明らかにするという手法も存在することを強調している[@UCILAB2020]。


# ブラックボックス

ブラックボックスとはそもそもサイバネティクスの中でAshbyが挙げたとされる概念である。

## ブラックボックスの4分類

<!-- 1. ????：起きている現象が・・・・何だ？ -->
1. 知識的：技術に対する知識の欠如
1. 身体機能的：起きている現象が人間の生理的/認知的限界を超えている
1. 言語的：何が起きているかはわかっているが、その現象を言語化できない
1. 社会的：契約や法律によって技術の内部を覗き見ることが不可能である

### 理解不可能性：知識的ブラックボックス

例えばAppleの最新のMacbookProに入っているCPUのことを考える。我々は普段CPUがどう動いているかについてわからないままにCPUを使うことができてしまっている。
わからない最もシンプルな理由は、CPUとは何かについて勉強してないので、それがどういうものかわからない、ということである。このカテゴリで重要なのは”学習すれば解決できる”という話である。
この例えを使っている例としてはPrikkaとHerzのサーキットベンディングをメディア考古学的実践として捉える論考がある。彼らは次のような図としてアマチュアが中身の動作原理を理解しないまま、回路をつなぎ変えることで別の目的に（例えば、幼児向けおもちゃをノイズ楽器へと）再利用するモデルを示している。彼らがNon-expertという用語を使っていることからも、ここでの意図は改造者に電子回路の詳しい知識がないことに重きが置かれていることがわかる。


### 知覚不可能性：身体機能的ブラックボックス

しかし、私はCPUの基本的な仕組みや構成方法を知っているが、CPUが実際に動いているところを眺めたところで、いまCPUのこの機能が使われているのだということを知覚することは不可能だ。仮に自分でトランジスタを一つ一つはんだ付けしていってCPUを自作したとしても、それが正しく動いている”らしい”と判断できるのは、結局のところ入力に対して期待した出力が出てくることで確かめている＝ブラックボックスとしての利用であることに変わりはない。
もっと単純な例で、１つのトランジスタが動く場合を考える。トランジスタがゲート-エミッタ間を流れる電流に伴ってコレクタ-エミッタ間を流れる電流を増幅させる作用があることを私たちは勉強で知っているし、不純物の混入で余った/足りなくなった電子が電圧によって移動して～というミクロスケールでの動作の概念についても理解している。しかし私たちは実際に電子が移動している様をこの目で確かめたわけではない。結局これも、入力に伴って出力が変化した、という入出力の対応をもって確かめているに過ぎない。

これは突き詰めれば人間の身体機能が限界にある、といって良いだろう。我々は電子が移動する様を直に見ることはできないし、3GHzで変化するHIGH/LOWの電圧変化をリアルタイムのスピードで知覚することはひとまずできない。

ここで、1.の学習も人間の身体機能の一部なのでまとめても良いのではないかという考えもあるだろう。しかし、電子が移動する様を眺めるには何か（例えばオーグメンテッドヒューマン的に視力を改造するSF的処置が未来に可能になったとして）、外在的な要因で身体機能を強化することでなら可能になるだろうが、人一人が自らの力だけでそこまでの身体的変化を起こすことはまず不可能だろう。まあ、学習のための本とかだって立派なテクノロジーであって外部的要因でしょ、ということもできるのだが、ひとまずCPUの例では直感的に別種の要因であると言えそうなのでこのままにしておこう。

### 翻訳不可能性：言語的ブラックボックス

これは少しCPUの例では説明の仕方を変えよう。言語化不可能なことによるブラックボックス性といった時に筆者が想定しているのは、主に機械学習のモデルが下す判断の根拠を説明するのが不可能である、といった問題である。
与えられた画像がイヌかそうでないかを判断するプログラムがあったとしよう。人間が画像認識のアルゴリズムを組み合わせてモデルを構築した場合、プログラムのソースコードにおける関数や変数の名前は人間が解釈可能なものとして残っている。そのため、何かイヌじゃない画像を入れたのに結果がイヌと判断されてこれはおかしい、となった時に、少なくともどの時点での計算での結果がおかしいかがわかり、構築したモデルが正確でない要因をある程度判断することができる。
これが、学習ベースの推論の場合は、モデル自体は大量の並列化された非線形関数とそれ同士の入出力重みづけが並んでいるだけで、学習に伴ってその重みづけのパラメーターが少しづつ変化していくだけだ。イヌかどうかを99%近くの確率で判断できたとしても、中身を開けたとしても”なぜ”イヌと判断できるのかの理由はわからない。まぁ実際にはCNNのような二次元の重み付けをつけるようなモデルでは、最終的に重みづけの分布も二次元になるのでなんとなく、この層ではこういう特徴を抽出しているっぽい、とかいう解釈らしいこともできるし、機械学習の判断として実用的に（例えば社会的信用スコアをAIで出す時に根拠が出せないのは結構困るので）モデルの説明をするような研究も進んでいる。 https://tjo.hatenablog.com/entry/2019/12/19/190000
もちろん、別に機械学習モデルでなくても、例えば我々の目や脳が何かを見た時にあれをイヌだとかイヌじゃないとか判断していたとして、脳の電気信号をいくら計測したところで”なぜ”イヌかがわかるわけじゃないので、機械学習の方が劣っているとかそういう話をしたいのではここではない。そもそも前掲の記事でも紹介されているように説明する必要性がないという議論もあるhttps://arxiv.org/abs/1811.10154　。
重要なのは1とも2とも違って、人間が頑張って学習すれば剥がれるブラックボックスでもないし、人間の身体機能をいかに強化したところで解決する問題でもないという意味で種類が違う、ということである。


### アクセス不可能性：社会的ブラックボックス

さて、1,2のCPUの例えに戻る。私はCPUの仕組みを勉強していて動作原理をある程度理解しているが、最新のMacbookProに搭載されているCPUの構造を知ることはできない。なぜなら最新のMBPに搭載されているM1チップというAppleが独自に設計したチップの仕様はオフィシャルには公開されていないので知ることができない、ということである。
こうしたことは大概のプロプライエタリなソフトウェアでも同じことがいえ、ブラックボックスの入出力の対応を確かめる＝リバースエンジニアリングによってある程度内部の仕組みを知ることができる可能性はある。しかし、場合によってはエンドユーザー利用規約でリバースエンジニアリングが禁止されており、中身を知ろうとしたことがバレれば訴えられる……こともあるかもしれない。
1~3のブラックボックスと明らかに異なるのは、誰かが意図的にこのブラックボックスを作っていることだ。それは経済的、政治的な都合などによって生み出され、社会的に存在する権力構造を利用して存在し続けている。
なので、コンピューターを自由な装置として利用するべきであるという方向性での、メガプラットフォーム批判に使われる材料になる。iPhoneという小さなコンピューターを、OSレベルでカスタマイズすることはできず、Appleの公証を受けたアプリケーションしかインストールすることができない、とかに対して。

## ブラックボックスの混用

さて、例えばこの4種類のブラックボックスが混ざって使われている例を少し見てみる。
例えば緒方の「コンヴィヴィアル・テクノロジー」（2021）の序章には以下のような文が並ぶ。


> ～わたしたちはもはや、自分一人でスマホを作ることはできないし、SNSのタイムラインがどのようなアルゴリズムで表示されているのかを理解することもできない。あるテクノロジーのメカニズムやアルゴリズムがブラックボックス化することは、人々をブラックボックスを作る側と使う側、管理する側とされる側に知らず知らずのうちに分断してしまう。ブラックボックス化された道具がますます便利になり、不自由を感じなくなればなるほど、ここをもっとこうしたいとか、もっと別のこんなものがあったらいいのにといった創造的な発想が生まれなくなってしまい、道具を自分なりに改良したり、新しい道具を自らつくりだそうという主体性がだんだんと奪われていくのである。(34p)

> ～行き過ぎた専門化は化学をブラックボックス化し、知識への盲信（または不信）を招く、そうしてわたしたちは、自ら世界と関わり、考え、判断し、意思決定する能力を徐々に失っていくのである。(55p)

ひとつ目の文章は1:学習と4:社会的の2つの要素で構成されているように思えるが、ふたつ目の文章は1に重きが置かれているように思える。自分一人でスマホを作ることができないのは、やろうと思えばできる事だが自分一人でやろうとすると、膨大な量の勉強が必要なことに加えて、作るのに必要な道具や設備の必要性など、コストパフォーマンス的な面からも現実的でなくなるからだ。だが、実際には作れなくはない。実際、肥大化し過ぎた科学の知識体系を自分の手で可能な限りゼロから作る事で明らかにする試みとしてはトマス・トウェイツの「トースター・プロジェクト」のような例がある。
だが一方で、SNSのタイムラインが表示されるアルゴリズムを我々が知ることができないのはその技術を理解するのに必要な知識量だけの問題ではなかろう。めちゃくちゃプログラミングをやっているFacebook社のエンジニアもTwitterのタイムラインが表示されるまでの仕組みを完全に知ることはできない。




インビジブルコンピューターとは、認知言語学てきな思想に基づくインターフェースを改善するための思想だったと言える。

そこで重視されてきた（と思われてきた）のは身体感覚と言語機能の接続であり、適切な概念モデルを元にシグニファイア（シニフィアン）を作ることが良いインターフェースデザインの方法だったと言える。

しかし一方でこれらの思想の中で軽視されてきたものとして、ノーマンはインフラストラクチャの重要性を指摘していたことを思い出すべきだ。

すなわちある集団に対してのインターフェースデザインをするためには、その集団で共有されている概念モデルを（例えばエスノグラフィなどによって）同定し、

