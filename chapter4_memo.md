
音楽のためのプログラミング言語は既存の文献では、Computer Music Language[@McCartney2002;@Mcpherson2020]、Language for Computer Music[@Dannenberg2018]、Computer Music Programming Systems[@Lazzarini2013]などの呼ばれ方がされているが、それぞれの語の使用に明確なコンセンサスがあるわけではない。その中でも敢えて筆者がComputerという語を使わない理由のひとつは、Computer Musicという語が、コンピューターを用いることで新しい音楽表現を追求する歴史的な取り組みの中にある、特定の音楽様式と結びついてしまうことを避けるためだ。既に述べたように、今日ではあらゆる音楽制作と再生のためにコンピューターが用いられている以上、あらゆる音楽が**弱い意味でのComputer Music**と呼ぶことができる。しかしそれらの多くはコンピューターでなければ不可能な、コンピューターというメディア固有の表現を行っているわけではない。同様に、たとえばFaust[@Orlarey2004]のような、信号処理のアルゴリズムを抽象化することに特化したプログラミング言語は新しい音楽表現を必ずしも目的としていないが、その技術的要素の多くはComputer Musicのための言語と共通するところがある。またPLfMという枠組みを用いることで、これまでの文献では比較対象に入れられること自体が少なかった、MML:Music Macro Languageのような、五線譜上の記法を直接的にテキストに置き換えたような、単にコンピューター上のテキストというフォーマットで音楽を表すことを目的とした言語たちも、チップチューンのような広い意味でのコンピューターを用いた音楽文化を作るための要素として議論の土台にあげることができる。

加えて、Programming EnvironmentやProgramming Systemといった語を用いない理由も説明しておこう。これは、音楽のためのプログラミング言語といった時に、たとえばMaxのような、ある特定のアプリケーションを想像するニュアンスを抑えるための選択だ。たとえば、汎用プログラミング言語の理論においては、プログラミング言語、と言った時にはその言語を実行するためのソフトウェアやプログラムのことを必ずしも指していない。たとえば同じC++という言語であったとしても、それを実行するソフトウェア（コンパイラ）はGCC、Clang、Microsoft Visual C++といったように複数存在し得るからだ。これらのコンパイラは、どれもC++の厳格な言語仕様で定まっている通りの動作をするが、言語仕様で未定義とされてる動作はそれぞれ異なるし、コンパイラが出力する実行バイナリ（≒アプリケーション）の中身は同じソースコードだったとしても異なる。音楽プログラミング言語においては、基本的にある言語＝特定のアプリケーションであることがほとんどだが、根本的にはアプリケーションの設計実装という作業とプログラミング言語の設計実装という作業は異なり、本研究が対象にしたいのは言語の設計なのだ。こうしたニュアンスを込めて筆者はEnvironmentやSystemという語を用いないことにした。極論を言えば、Faustのような厳密に意味論が定義されている言語においては、コンピューターを用いなくてもそのソースコードを手作業で解釈し実行することが可能だということを考えれば、プログラミング言語はコンピューターを使うための道具であることは間違いないにせよ、人間が直接的にバイナリを操りプログラムを構築するには限界があるという理由で開発されているという意味で、逆説的に徹頭徹尾人間のための道具でしかない。だからComputer Music Languageとも、Computer Programming Languageとも、呼ばずに、ただ音楽のためのプログラミング言語：Programming Language for Music、PLfMなのだ。

1970年代の区切りは2章で見てきたコンピューターをメタメディア装置として扱う思想の始まりと、パーソナルコンピューターの登場という2種類の出来事である。

そもそも音楽プログラミング言語の祖先となるソフトウェアMUSICが開発されたのは正解で最初の(汎用)プログラミング言語FORTRANが作られた翌年であり、当然1章で見たアラン・ケイらによる対話的プログラミング環境や豊富な入出力インターフェースを備えるよりもずっと前のことである。
なので、必然的に音楽ソフトウェアのプログラミング自体も機械語を直接入力するかアセンブリ言語(機械語の命令をテキストと1対1対応させたプリミティブなプログラミング言語のようなもの)しかなかったし、そのソフトウェアに対する入力データ（≒楽譜）も同様の形式を取らざるを得ないものだった。

つまり、1950〜1970年代の音楽プログラミング環境は大まかにいってコンピューターで音楽を作るためのソフトウェア全般の祖先にあたるものであって、必ずしもプログラミングという行為やテキスト入力という形式の固有性を積極的に取り入れたものではない、ということだ。

逆に、70年代以降の音楽プログラミング言語/環境はマウスや(文字入力や、ピアノ鍵盤どちらにせよ)キーボード入力といった直感的（WYSIWYG的）なインターフェースが選択肢として存在する中で敢えてプログラミングという手段を使うものとして設計されてきた、という違いがあると言えるだろう。プログラミング環境であっても、GUIの誕生はMax(Puckette)を代表としてテキストインターフェースだけでなく、入出力を持つボックスをマウスで繋いでいくような形式など、テキストに留まらない形式でのプログラミング行為を可能にした。これは同時に、出力された信号などもオシロスコープのようなグラフィックとしてフィードバックが返ってきたり、パッチ（Maxにおけるプログラムのこと）中にスライダーのような、プログラムされたソフトウェアを操作するためのインターフェースが同居していたりといった、それまで存在していた "プログラムを構築するステップ"と "構築されたプログラムを使用するステップ"に明確な境目が無くなっていく歴史でもある。


また、1990年代の区切りは、パーソナルコンピューターが専用のサウンドチップなしに、CPUだけで音声信号処理をリアルタイムで行えるようになったこと、そして汎用プログラミング言語の理論が音楽向けの言語にも流入し始めたことの2種類である。


コンピューターアーキテクチャのスタンダード（もっと言ってしまえば、x86アーキテクチャ）が定まるまでのプログラミングは、特定のハードウェアのための特定のプログラムを作るという側面が大きく、書かれたソフトウェアが様々なプラットフォームで使い回しが効くということでもなかったことも頭に入れておくべきだろう。汎用プログラミング言語はそれまでの実在するハードウェアに対する命令列を可読性のあるテキストデータから出力するためのソフトウェアという側面だけでなく、ラムダ計算（引用）のような、計算過程自体を数学的になるべく普遍的になるように記述する代数学の理論との接続を見せるようになり、LISPやML、Haskellに代表されるような関数型プログラミング言語のパラダイムが発生してきた。
そしてこうした分野で培われたプログラミング言語の理論は現在ではFaustやKronosを代表とする、関数型でかつ音楽や音声処理のための言語の理論的基盤としても用いられるようになっている。


つまり2020年代現在において、本論文が定義する音楽プログラミング言語とは、**コンピューターを用いて音楽を生成するためのソフトウェア群に始まりつつも、並行して発展してきた汎用プログラミング言語やその理論を取り込みつつ発展してきたソフトウェアやツール**のことを指す。なので、Maxのように前者の流れを強く汲むものは、Dannenbergが言うように、言語体系とランタイムやライブラリ、開発/実行環境があらかじめ切り離せない形式(＝実装そのものが仕様)となっていることが多い。
逆に、汎用プログラミング言語の理論をベースに構築された言語、例えばExtemporeやFaust、Kronosでは、言語仕様は言語仕様として独立しておりランタイムが存在しないーあるいは複数のランタイムの実装があり得る、そのほか、決まったIDEが存在しなかったり、複数の開発/実行環境が存在するといった構成になっているものがある。
