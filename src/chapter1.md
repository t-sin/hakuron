# イントロのイントロ

2021年9月。北九州市の植物園でこのイントロダクションを書いている。

植物園、というか自然公園みたいなこの場所にはフリーランスの仕事で来ている。公園を大きく使ったナイトウォークのようなイルミネーションのようなイベントで、そのための音楽やSEを流すためのシステムを作る仕事である。仕事の半分くらいはスピーカーをどこに配置するかとか、どの機材を使うかとかそういう話なのだが、もう半分はその沢山あるスピーカーにどう音を割り振ったり、パソコンを起動したら自動的に音が鳴り始めるようにするためのプログラムを作る作業になる。

制御のためのソフトウェアはCycling'74社のMaxという音声処理が得意なマルチメディアプログラミング環境で構築している。長い歴史を持ち、現在音楽のためのプログラミング環境としては（知る限り）最も多く使われており、個人的には2015年から使い始めたこのMaxというソフトウェアを使うと、例えば展示空間にスピーカーを10個とか（それも、いわゆるサラウンドとかとは全然違うレイアウトで）配置してそれぞれに違う音を同期して流したりすることができる。あるいは、映像を生成するコンピュータからネットワーク経由で特定の信号を受け取ったら特定の効果音を流すようにしたり。

なんだか言葉にすると大したことがない仕事のように聞こえる。実際、プログラムを書く作業自体は主観的には大したことがないのだ（ソフトウェア特有のニッチな問題やらバグは細々あるにしても）。こんな作業でお金をもらってしまっていいんだろうかと思う時もある。

しかし実際のところ似たような仕事ができる人はそこまで多いわけでもないらしい。例えば、仕事を受けようとしたが予定が埋まっているときに別の似たような職能を持った人を紹介しようと思っても、パッと思いつく人はそう多くない。

これは、自分がこうした仕事に慣れすぎてしまったのだろうか。半分はそうなのだろうが、この仕事をしているとやはり考えざるを得ない疑問は、コンピューターはなんでもできる装置のはずなのに、たかだか沢山のスピーカーに同時にたくさん音楽を流すぐらいのことに、どうしていちいちこんな専用の（しかも有料の）ソフトウェアを使ってカスタムツールを使ってプログラムを作るような手間がかかる作業になってしまうのだろう、ということなのだ。

これは別に、使うスピーカーが多いから必要なコンピューター処理能力が大きい、という話でもない。例えば、映像インスタレーション作品でどうしてもフォーマット的に3chのスピーカーを制御したい、となったときにも、大体10chの時と同じくらいの面倒臭さが発生する。2chが3chになったりするだけで、普通の音楽制作ソフトウェアでは扱いづらくなる。なんでmacOSでファイルを選択してスペースバーを押したら音声ファイルが再生されるように、物理的なセンサーに触ったら音声ファイルを再生する程度のことに労力が必要なのか。なんでエクセルファイルをちょっと編集するぐらいの手間で10chのスピーカーに音声ファイルを割り振れるようにならないのか。

この疑問こそが、おそらくはインフラストラクチャやフォーマットの持つ力というものの説明なのだろう。つまり、人々は2chのステレオ音声のフォーマットがすでにあるから2chステレオで音楽を作る。作るためのツールも2chが一番主流なのでそれが最も作りやすいように良心的な配慮をしてしまう。それに、いかに音楽や芸術表現が新しさを欲するものだとしても、とりあえずはその2chのフォーマットの中で表現が可能な新しさであれば問題にはならない。そして、別に3ch以上の音声フォーマットも表現として”不可能なわけではない”。ただ、ちょっと手間がかかるのだ。

技術決定論者/あるいはマルクス主義者風の言い方をすればインフラストラクチャ:下部構造が上部構造ー、つまり音楽表現とかを規定するということになるのだろうか。おそらくはそうではない。インフラストラクチャは表現を完全に縛りはしないが**誘導**する。そしてその誘導方向は既存の上部構造によって作り出されるものであり、互いに循環し合いながら徐々に路面は踏み固められていく。

---

本論文は、音楽のためのプログラミング言語mimiumの設計と実装を通じて、あるべきコンピューターと音楽の関係性を考え直すものだ。

2021年現在、音楽を聴いたり、演奏したり、作ったりする上で、コンピュータが一切関与しない、という状況を考えるのは難しくなっている。作曲にはDAW（Digital Audio Workstation）ソフトウェアを使用し、配信にはApple MusicやSpotifyのようなストリーミングサービスを通じて、デジタルデータという形で音楽は配布される。最終的に、コンピューターやスマートフォン上のソフトウェアでそのデータをデコードし、音はスピーカーへと送られようやく空気の振動になる。スピーカーの中にさえデジタル信号処理(DSP:Digital Signal Processing)用のチップが入っていて計算によって音質の調整をしていることも珍しくはない。2020年以後のコロナウィルスの影響も含めれば、クラシック音楽のコンサートさえも録画録音されたものが配信されることの方が多くなってしまったかもしれない。

とかく音楽文化を見れば、マーク・ワイザーの提唱したユビキタス（Ubiquitous:偏在する）・コンピューティングの概念は字義通りには達成されたようにも見える。


他方、音楽文化の需要のあり方という視点でテクノロジーとの関わり方を見てみると、どれだけ高度なテクノロジーを用いて生成された音声も、最終的には何らかの5~10分の音声ファイルとして編集され、ほとんどの場合スピーカーやヘッドホンという2chの音波を発する装置によって受容され、録音技術黎明期からの受容の形式から大きく変化していないと言える。

録音技術登場時と現在で決定的に違う点として、現在音楽が制作されてから再生されるまでに、ほとんどの場合何らかの形でコンピューターが介入していることが挙げられる。音楽録音や制作過程においてはDAW(Digital Audio Workstation)ソフトウェアが、配信過程においてはSpotifyやApple Musicのようなプラットフォームとそれを支えるサーバー群、再生過程においてはラップトップやスマートフォン、さらにはDSP内蔵のスピーカーやヘッドホンの音声処理チップといった様に広義のコンピューターが音声を処理している。にも関わらず、本来万能な装置であるはずのコンピュータのポテンシャルは最終的に2chの音声信号を出力するためにしか用いられていない。


作曲のための環境という視点に絞って話せば、DAWを始めた今日の音楽制作ソフトウェアはかつて電子音楽家のOval(Markus Popp)が「音楽制作ソフトウェア環境は、普遍性という側面を持っていながらも、過去の音楽的遺産、伝統的な音楽の理解方法のコンテナとして機能しているにすぎない」[@Popp2001]と言ったように、録音音楽の慣習に基づいたワークフローのシミュレートから（時代に伴い緩やかな逸脱を見せはじめつつも）脱することがない。

OvalはCDの読み取りエラーを積極的に音楽に取り入れるような、グリッチと呼ばれる手法を用いる作曲家で、2000年代にovalprocessという自分のためのカスタム音楽制作ソフトウェアを制作し、ソフトウェア自体を音楽作品（さらにそれを超えて、レーベルやエディションに相当するもの）にしてしまうことを試みた。彼のovalprocessに関する論考で興味深いのは、テクノロジーが新しい音楽を生み出すと言った技術決定論的な言説に限らず、規格やフォーマットといった制度論に対して強く自覚的になっている点だ。いくつか引用しよう（いずれも強調は筆者による）。

> オヴァルは、デジタル制作メディアにおける、一つの典型的なワークフローの**スタンダード**を、攻撃的に使用する。

> 〜私の音楽は、改定された「音楽Ver2.0」という、新しい決定的な**スタンダード**を導入しようとしている。

> 音楽制作ソフトには潜在的なリベラル的傾向があるにもかかわらず、私はその「クリエイティヴ」な可能性ではなく、ワークフローの大規模な**規格化**に焦点を当てている。

> 私の個人的アプローチは、**スタンダード**を攻撃的（オフェンシヴ）に使うことに基づいている。デジタル（音楽）メディアを「実験的」に使用するよりも、スタンダードーーファイル・フォーマット、ファイル・トランスファー・プロトコル、圧縮スタンダード、コーデック（データの圧縮／慎重、COmpression／DECompressionの略）、オペレーティング・システムーーの方が、私の作業過程において重要な要素なのである。それは、これらのスタンダードが、何がコンピューターで可能であるかを決定する**土台**であるからだ。

> 音楽制作ワークフローの論議に対する大衆の認識と接し方が変わらなければ、「独自」のソフトウェアを作る利点は疑わしく、何も解決しないだろう。電子音楽制作の根底にある**技術的スタンダード**に関する論議を、徹底的に見直す必要がある。カスタム。ソフトウェアを作ったとしても、それを廃れた概念や、時代遅れの音楽パラダイムに従ってデザインし、使用し続けたのでは、何の解決にもならないのだ。

こうした議論を見ると、Ovalがグリッチのようなアプローチを取っていたのは、ツールを意図的に誤用したり、アマチュアリズム的に「あちこちいじくり回す」[@Cascone2009]ことによって隠された内部構造をあらわにしたり、無目的に聞いたことのないノイズ音を生み出したりすると言った目的でも、コンピューターのメディウム固有性としてマノヴィッチが挙げる、あらゆるタイプのデータを数値として表象する[@Manovich1999,p8]ことを逆手にとって、データを意図的に誤った読み替えをして新しい音楽を作るということに着目していたわけでもない。

むしろ、全てが数値として表象されるときに、見えないところで大企業や標準化団体がその意図を直接的には見えない形で埋め込み、創作者に対して間接的に影響を与えていることへのカウンター行為としての積極的な規格からの逸脱や、オルタナティヴな野良規格の構築という行為だったと見ることができるだろう。


最終的にovalprocessはいくつかのインスタレーション展示を除いて公にリリースされることはなかった(引用)。


コンピューティング文化の研究では音楽は比較的先進的なテクノロジを先取りしてくるという議論もある。（参照先忘れたので考える、ジャックアタリとか、これゲームさんぽの水野佑さんでしたね）


<!-- だが、本論文ではあえて、現在の音楽文化のコンピュータの関係性(音楽におけるコンピュータの使われ方？)は本当に**マトモなのか**ということを大きなテーマとして考え直す。 -->

まず、コンピューターを用いて音楽の新しい表現を開拓していく、という進歩的な歴史の見方を否定したいということ。

それから、コンピューターも音楽も、人間によって生み出された物というよりも人間同士を仲介する道のような存在ではないかという意味合いだ。

# 方法論

音楽プログラミング言語、というよりも、コンピューターを創作に用いるための道具を研究するにあたって問題になるのは、それをどう評価するかということだ。

典型的には、作ったツールをユーザーに使ってもらって統計的に評価を出すという実証主義に基づいた量的な研究方法がある。
これらの方法には、特にヒューマン-コンピューターインタラクションにおける創作支援ツール(Creativity-Support Tool,CSTと略されることも)においては慎重になるべきである（なんか引用）。

ありもしない「ユーザー」を想定してしまうこと
追試による反証可能性を試したところで…という問題

質的研究方法（大谷など）　臨床医学の方で主に発達している。最近はHCIなどでもJacobsによる長期ユーザーテスト

あくまで（OSSで公開しているし、インフラ的な役割を重視しているとはいえ、）自分の製作を自分が検証する方法

Magunusson On Epistemic Tools(まぁこれもインタビュー調査とかしているけれども)

究極的には、今後音楽プログラミング言語を作る人のための道標になれると嬉しい。それも、単に作るための技術的知識だけでなく、なぜ作るのかということも含めた

大谷の議論にも、個人的制作のバックグラウンドを記述しておくことは資料としても有益なので記述しよう

## mimium制作までのバックグラウンド

はじめに言語を作ろうと考えたのはSFPC

制度論としてのメディアアート、展示というインフラストラクチャ、カウンターカルチャーとしてのテクノロジーアート

## メディア考古学、スペキュラティブデザイン、そして音楽土木工学へ


# 本論文の貢献

本論文を通じて学術的に貢献する内容は以下のようになる。

まず、音楽プログラミング言語の存在論の提示だ。音楽プログラミング言語は歴史的にコンピューターを用いて音楽を生成するための技術としてスタートしつつも汎用プログラミング言語の理論を取り込んで発展してきたことにより、一重に音楽のためのプログラミング言語/環境といってもその応用範囲や想定される使用方法、さらに内部の実装方法までが多岐に及び、単純な比較をすることが難しい。また、評価のための語彙も"表現力が高い" "効率的" "汎用的"などの言葉が共通認識の無いまま慣例的に使われており、実際に何を意味するかもはっきりしないことがある。本稿ではまずこのような、”音楽プログラミング言語とは何か”、”音楽プログラミング言語にはどんな種類があるのか”、”音楽プログラミング言語の特性をどう記述できるのか”といった概念を整理して提示する。

2つ目は、筆者が設計/実装した自己拡張性の高い音楽プログラミング言語"mimium"についての設計思想とその具体的な実装を提示することだ。mimiumは先述した音楽のためのプログラミング言語の歴史を見直し、現在の技術的状況、あるいは音楽文化の上で、これまで十分には足りていなかった、音楽のために特化した最低限の言語機能を備えつつも、汎用プログラミング言語と同様の自己拡張性を備えた言語となるように設計されている。

3つ目は、今後は音楽プログラミング言語を音楽を作るためのツールとしてだけではなく、メディウムとして流通させるためにも利用していくべきだという主張である。録音技術（音響再生産技術）に端を欲した音楽のフォーマットは現在空間音響技術のためのフォーマットによって、原音再現という従来の明確な一つの目標を失いつつある。その環境でコンピュータ上の表現の自由度を最大限担保するためにはプログラミング言語そのものを音楽のためのフォーマットすることが必要になってくる。


4つ目は、音楽プログラミング言語自体を学術的な研究とする際の異なる方法論の提示だ。音楽プログラミング言語の研究自体は、人文学的な動機で研究をされつつも、基本的には作ることで問題を解決する（≒できなかったことをできるようにする）という、いわゆるIMRaDな形式を取ることが多かった。本論文ではそうではなく、問題がなんなのかははっきりとはわからないままに作り始めることで、事後的に問題が浮かび上がってくる、質的研究法の中で言われるReflexivity（自己反映性[^reflex]）、つまり自分の研究内容によって自分自身が変化することを重視した研究である。今回の研究であれば、初めは音楽プログラミング言語という範囲の中での問題点という狭い視野で作り始めたものが、最終的には音楽におけるコンピューターの使い方全般の問題や、音楽流通におけるデジタルフォーマットの問題、テクノロジーにおけるブラックボックス性の是非といったより広い問題意識へと広がっていく過程をオートエスノグラフィーの形で（？）示す。

[^reflex]: Reflexivityという言葉は再帰性や反射性という訳語があてられることも多い。本論文中では計算機科学の用語としての再帰（Recursion）との不要な混同を避けるため、また、プログラミング言語において実行環境（コンパイラやインタプリタ）の挙動自体を実行コードからメタ的に操作できる機能のことをReflectionと呼び、日本語としては自己反映言語や自己反映計算と呼ばれることもあり、意味合いとしてはより類似しているように思われるため、自己反映性という言葉を用いる。



# 構成

## 三重の歴史の提示




第2章以降は以下のような構成で論じる。本論文全体の構造を図nに示した。

第2章ではコンピューターが単に計算の自動化のための装置から、70年代にメタメディア装置にへと変化しさらにその先にユビキタス・コンピューティングに代表される、コンピューターを不可視（Invisible）にする思想が醸成される過程を示す。
ここではメタメディアとしてのコンピューターが、ユーザーがプログラミングによって自分で機能を組み替えられるようになっていたことに本質的な点があったことを指摘する。その一方で、当時のメタメディアの音楽的な利用が既存の音楽表現のレールに乗っていることで成立していることにも言及する。


第3章では、現在の音楽インフラストラクチャに大きく影響を与えた録音技術